{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villasen/colab_notebooks/blob/master/Keras_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfXFsAnRkn9",
        "colab_type": "text"
      },
      "source": [
        "#Urban dataset download and file structure setup for train, validation, and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mpdiRj4-Fs",
        "colab_type": "code",
        "outputId": "cbc6c643-ab79-4d52-b6dc-83926ddd1d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/villasen/small-urban-sound-dataset.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'small-urban-sound-dataset'...\n",
            "remote: Enumerating objects: 9719, done.\u001b[K\n",
            "remote: Counting objects: 100% (9719/9719), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9324/9324), done.\u001b[K\n",
            "remote: Total 9719 (delta 398), reused 9713 (delta 394), pack-reused 0\n",
            "Receiving objects: 100% (9719/9719), 259.08 MiB | 27.25 MiB/s, done.\n",
            "Resolving deltas: 100% (398/398), done.\n",
            "Checking out files: 100% (10185/10185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qrPrM21WXMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/small-urban-sound-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD6xOVD6ho2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/target_npy_files/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz67Mm9GIUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        },
        "outputId": "f9535e79-a03a-4b45-dcb8-746d48be677c"
      },
      "source": [
        "#from preprocess import *\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow\n",
        "import scipy\n",
        "import os, shutil\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "target_dir = '/content/target_npy_files'\n",
        "#DATA_PATH = \"small-urban-sound-dataset/tiny-dataset/\"\n",
        "DATA_PATH = \"small-urban-sound-dataset/combined_datasets/\"\n",
        "os.mkdir(target_dir)\n",
        "\n",
        "def wav2mfcc(file_path, max_pad_len):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=10, n_fft=640, hop_length=320)\n",
        "    pad_width = max_pad_len - mfcc.shape[1]\n",
        "    if pad_width < 0: \n",
        "      print(mfcc.shape[1])\n",
        "      print(pad_width)\n",
        "      print(\"error in \"+ file_path)\n",
        "    \n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    return mfcc\n",
        "\n",
        "  \n",
        "  \n",
        "def get_labels(path):\n",
        "    labels = os.listdir(path) \n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices, to_categorical(label_indices)  \n",
        "\n",
        "\n",
        "\n",
        "               \n",
        "def save_data_to_array(path=DATA_PATH, max_pad_len=51):\n",
        "    labels, _, _ = get_labels(path)\n",
        "\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        mfcc_vectors = []\n",
        "\n",
        "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "        for wavfile in wavfiles:\n",
        "            if label == '_background_noise_' : break\n",
        "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
        "            \n",
        "            mfcc_vectors.append(mfcc)\n",
        "        np.save('/content/target_npy_files/' + label + '.npy', mfcc_vectors)\n",
        "        print(label)\n",
        "        print(len(mfcc_vectors))\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "def get_train_test(split_ratio=0.9, random_state=42):\n",
        "    # Get available labels\n",
        "    labels, indices, _ = get_labels(DATA_PATH)\n",
        "\n",
        "    # Getting first arrays\n",
        "    X = np.load('/content/target_npy_files/' + labels[0] + '.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    \n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load('/content/target_npy_files/' + label + '.npy')\n",
        "        \n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "        \n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "save_data_to_array(path=DATA_PATH, max_pad_len=51)    \n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 10, 51, 1)\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sheep\n",
            "40\n",
            "sea_waves\n",
            "40\n",
            "train\n",
            "40\n",
            "airplane\n",
            "40\n",
            "water_drops\n",
            "40\n",
            "cat\n",
            "40\n",
            "pig\n",
            "40\n",
            "pouring_water\n",
            "40\n",
            "clapping\n",
            "40\n",
            "mouse_click\n",
            "40\n",
            "gun_shot\n",
            "374\n",
            "cow\n",
            "40\n",
            "clock_tick\n",
            "40\n",
            "chainsaw\n",
            "40\n",
            "car_horn\n",
            "40\n",
            "washing_machine\n",
            "40\n",
            "engine_idling\n",
            "1000\n",
            "clock_alarm\n",
            "40\n",
            "church_bells\n",
            "40\n",
            "insects\n",
            "40\n",
            "thunderstorm\n",
            "40\n",
            "laughing\n",
            "40\n",
            "hen\n",
            "40\n",
            "vacuum_cleaner\n",
            "40\n",
            "children_playing\n",
            "1000\n",
            "chirping_birds\n",
            "40\n",
            "air_conditioner\n",
            "1000\n",
            "rain\n",
            "40\n",
            "breathing\n",
            "40\n",
            "street_music\n",
            "1000\n",
            "sneezing\n",
            "40\n",
            "siren\n",
            "929\n",
            "keyboard_typing\n",
            "40\n",
            "toilet_flush\n",
            "40\n",
            "Helicopter\n",
            "40\n",
            "rooster\n",
            "40\n",
            "brushing_teeth\n",
            "40\n",
            "snoring\n",
            "40\n",
            "can_opening\n",
            "40\n",
            "dog_bark\n",
            "1000\n",
            "jackhammer\n",
            "1000\n",
            "wind\n",
            "40\n",
            "drilling\n",
            "1000\n",
            "coughing\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi_wRLjZgBWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "#save_data_to_array(path=DATA_PATH, max_pad_len=51)    \n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 10, 51, 1)\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvG5N6W6MRLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/target_npy_files/*.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWZNjHYTtLnS",
        "colab_type": "text"
      },
      "source": [
        "# Building DS-CNN model using Keras framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWsjPl-K0IE4",
        "colab_type": "code",
        "outputId": "209f0a02-ec89-463a-f32e-2d353c59bb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7362
        }
      },
      "source": [
        "# Creating Keras sequential model\n",
        "#bn = 1\n",
        "BN=True\n",
        "model = models.Sequential()\n",
        "\n",
        "def dscnn_train():\n",
        "  # 1\n",
        "      model.add(layers.Conv2D(64, (4,10), strides=(2,2), padding='same', activation='relu', \\\n",
        "                #input_shape=(10, 49, 1)))\n",
        "                input_shape=(10,51,1)))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                                center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                                gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                                moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                                gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      # 2\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))  \n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      # 3\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      \n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "      # 4\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "      # 5\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:      \n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "      \n",
        "           \n",
        "      \n",
        "# Final layer\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.AveragePooling2D(pool_size=(5, 25), strides=(2,2), padding='valid', data_format=None))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Flatten(data_format=None))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Dense(64, activation='relu'))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      #model.add(layers.Dense(12, activation='softmax'))\n",
        "      model.add(layers.Dense(44, activation='softmax'))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      # Compilation step to choose loss function, optimizer and metric\n",
        "      # Configuring the learning process\n",
        "      model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "      #model.fit()\n",
        "      history = model.fit(X_train, y_train_hot, batch_size=100, epochs=200, verbose=1, validation_data=(X_test, y_test_hot))\n",
        "      \n",
        "      #plt.plot(history.history['acc'])\n",
        "      #Restarts layer sequence number \n",
        "      #K.clear_session()\n",
        "\n",
        "      acc = history.history['acc']\n",
        "      val_acc = history.history['val_acc']\n",
        "      loss = history.history['loss']\n",
        "      val_loss = history.history['val_loss']\n",
        "      epochs = range(1, len(acc) + 1)\n",
        "      \n",
        "      plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "      plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "      plt.title('Training and validation accuracy')\n",
        "      plt.legend()\n",
        "\n",
        "      plt.figure()\n",
        "\n",
        "      plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "      plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
        "      plt.title('Training and validation loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "      \n",
        "  \n",
        "dscnn_train()  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8732 samples, validate on 971 samples\n",
            "Epoch 1/200\n",
            "8732/8732 [==============================] - 22s 3ms/step - loss: 3.1351 - acc: 0.1260 - val_loss: 2.8180 - val_acc: 0.1483\n",
            "Epoch 2/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 2.6889 - acc: 0.1869 - val_loss: 2.8642 - val_acc: 0.1380\n",
            "Epoch 3/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 2.5641 - acc: 0.2198 - val_loss: 2.8417 - val_acc: 0.1617\n",
            "Epoch 4/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 2.4820 - acc: 0.2447 - val_loss: 2.5561 - val_acc: 0.2235\n",
            "Epoch 5/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 2.3873 - acc: 0.2775 - val_loss: 2.3877 - val_acc: 0.2698\n",
            "Epoch 6/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 2.3189 - acc: 0.3004 - val_loss: 2.2099 - val_acc: 0.3378\n",
            "Epoch 7/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 2.2489 - acc: 0.3247 - val_loss: 2.5562 - val_acc: 0.2915\n",
            "Epoch 8/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 2.1949 - acc: 0.3388 - val_loss: 2.4812 - val_acc: 0.2709\n",
            "Epoch 9/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 2.1547 - acc: 0.3475 - val_loss: 2.2085 - val_acc: 0.3429\n",
            "Epoch 10/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 2.0909 - acc: 0.3736 - val_loss: 2.1252 - val_acc: 0.3718\n",
            "Epoch 11/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 2.0427 - acc: 0.4004 - val_loss: 2.0264 - val_acc: 0.4408\n",
            "Epoch 12/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 2.0103 - acc: 0.4088 - val_loss: 2.1908 - val_acc: 0.3955\n",
            "Epoch 13/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.9532 - acc: 0.4342 - val_loss: 2.0838 - val_acc: 0.4192\n",
            "Epoch 14/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.8922 - acc: 0.4481 - val_loss: 1.9122 - val_acc: 0.4974\n",
            "Epoch 15/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.8704 - acc: 0.4648 - val_loss: 2.0855 - val_acc: 0.4573\n",
            "Epoch 16/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.8252 - acc: 0.4812 - val_loss: 1.8250 - val_acc: 0.5201\n",
            "Epoch 17/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.7884 - acc: 0.4961 - val_loss: 1.6693 - val_acc: 0.5623\n",
            "Epoch 18/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.7536 - acc: 0.5118 - val_loss: 1.7138 - val_acc: 0.5520\n",
            "Epoch 19/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.7372 - acc: 0.5187 - val_loss: 1.7296 - val_acc: 0.5489\n",
            "Epoch 20/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.6816 - acc: 0.5357 - val_loss: 1.7436 - val_acc: 0.5324\n",
            "Epoch 21/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.6691 - acc: 0.5427 - val_loss: 1.7274 - val_acc: 0.5530\n",
            "Epoch 22/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.6544 - acc: 0.5459 - val_loss: 1.8009 - val_acc: 0.5407\n",
            "Epoch 23/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.6055 - acc: 0.5589 - val_loss: 1.6950 - val_acc: 0.5685\n",
            "Epoch 24/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.5675 - acc: 0.5708 - val_loss: 1.9614 - val_acc: 0.5160\n",
            "Epoch 25/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.5538 - acc: 0.5725 - val_loss: 1.7079 - val_acc: 0.5767\n",
            "Epoch 26/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.5487 - acc: 0.5809 - val_loss: 1.5144 - val_acc: 0.5870\n",
            "Epoch 27/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.5196 - acc: 0.5894 - val_loss: 1.6155 - val_acc: 0.5850\n",
            "Epoch 28/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.4944 - acc: 0.5910 - val_loss: 1.7957 - val_acc: 0.5623\n",
            "Epoch 29/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.4682 - acc: 0.6110 - val_loss: 1.6784 - val_acc: 0.5850\n",
            "Epoch 30/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.4609 - acc: 0.6036 - val_loss: 1.4838 - val_acc: 0.6169\n",
            "Epoch 31/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.4467 - acc: 0.6038 - val_loss: 1.5493 - val_acc: 0.5984\n",
            "Epoch 32/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.4343 - acc: 0.6110 - val_loss: 1.4954 - val_acc: 0.6056\n",
            "Epoch 33/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.4175 - acc: 0.6150 - val_loss: 1.5457 - val_acc: 0.6148\n",
            "Epoch 34/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.3809 - acc: 0.6213 - val_loss: 1.7353 - val_acc: 0.6045\n",
            "Epoch 35/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.3699 - acc: 0.6293 - val_loss: 1.4811 - val_acc: 0.6344\n",
            "Epoch 36/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.3865 - acc: 0.6285 - val_loss: 1.5698 - val_acc: 0.6220\n",
            "Epoch 37/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.3729 - acc: 0.6300 - val_loss: 1.5703 - val_acc: 0.6179\n",
            "Epoch 38/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.3381 - acc: 0.6363 - val_loss: 1.6623 - val_acc: 0.5984\n",
            "Epoch 39/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.3252 - acc: 0.6460 - val_loss: 1.5062 - val_acc: 0.6303\n",
            "Epoch 40/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.3248 - acc: 0.6430 - val_loss: 1.4356 - val_acc: 0.6426\n",
            "Epoch 41/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.3218 - acc: 0.6488 - val_loss: 1.4893 - val_acc: 0.6385\n",
            "Epoch 42/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.2820 - acc: 0.6582 - val_loss: 1.4120 - val_acc: 0.6437\n",
            "Epoch 43/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.2814 - acc: 0.6537 - val_loss: 1.8926 - val_acc: 0.5726\n",
            "Epoch 44/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.2733 - acc: 0.6600 - val_loss: 1.5054 - val_acc: 0.6365\n",
            "Epoch 45/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.2601 - acc: 0.6624 - val_loss: 1.6000 - val_acc: 0.6056\n",
            "Epoch 46/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.2715 - acc: 0.6627 - val_loss: 1.4636 - val_acc: 0.6622\n",
            "Epoch 47/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.2631 - acc: 0.6648 - val_loss: 1.4660 - val_acc: 0.6509\n",
            "Epoch 48/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.2512 - acc: 0.6649 - val_loss: 1.4415 - val_acc: 0.6478\n",
            "Epoch 49/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.2257 - acc: 0.6702 - val_loss: 1.4706 - val_acc: 0.6581\n",
            "Epoch 50/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.2168 - acc: 0.6779 - val_loss: 1.5762 - val_acc: 0.6365\n",
            "Epoch 51/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.2172 - acc: 0.6728 - val_loss: 1.4684 - val_acc: 0.6457\n",
            "Epoch 52/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.2152 - acc: 0.6749 - val_loss: 1.3853 - val_acc: 0.6612\n",
            "Epoch 53/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.1967 - acc: 0.6789 - val_loss: 1.3843 - val_acc: 0.6550\n",
            "Epoch 54/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.1923 - acc: 0.6784 - val_loss: 1.4759 - val_acc: 0.6478\n",
            "Epoch 55/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.2025 - acc: 0.6785 - val_loss: 1.4630 - val_acc: 0.6571\n",
            "Epoch 56/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1729 - acc: 0.6844 - val_loss: 1.4336 - val_acc: 0.6787\n",
            "Epoch 57/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1558 - acc: 0.6859 - val_loss: 1.4891 - val_acc: 0.6632\n",
            "Epoch 58/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.1753 - acc: 0.6822 - val_loss: 1.5255 - val_acc: 0.6653\n",
            "Epoch 59/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1565 - acc: 0.6883 - val_loss: 1.5416 - val_acc: 0.6498\n",
            "Epoch 60/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.1607 - acc: 0.6899 - val_loss: 1.3903 - val_acc: 0.6756\n",
            "Epoch 61/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.1350 - acc: 0.6953 - val_loss: 1.3767 - val_acc: 0.6756\n",
            "Epoch 62/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.1290 - acc: 0.6956 - val_loss: 1.3756 - val_acc: 0.6684\n",
            "Epoch 63/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1571 - acc: 0.6893 - val_loss: 1.4315 - val_acc: 0.6581\n",
            "Epoch 64/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1392 - acc: 0.6951 - val_loss: 1.4936 - val_acc: 0.6777\n",
            "Epoch 65/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.1307 - acc: 0.6959 - val_loss: 1.3516 - val_acc: 0.6797\n",
            "Epoch 66/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 1.1429 - acc: 0.6965 - val_loss: 1.4291 - val_acc: 0.6601\n",
            "Epoch 67/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.1032 - acc: 0.7034 - val_loss: 1.3605 - val_acc: 0.6818\n",
            "Epoch 68/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1266 - acc: 0.6997 - val_loss: 1.4058 - val_acc: 0.6674\n",
            "Epoch 69/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.1005 - acc: 0.7003 - val_loss: 1.3224 - val_acc: 0.6838\n",
            "Epoch 70/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0961 - acc: 0.7050 - val_loss: 1.4025 - val_acc: 0.6880\n",
            "Epoch 71/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0816 - acc: 0.7043 - val_loss: 1.3235 - val_acc: 0.6838\n",
            "Epoch 72/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0867 - acc: 0.7025 - val_loss: 1.6275 - val_acc: 0.6426\n",
            "Epoch 73/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.0980 - acc: 0.7001 - val_loss: 1.4498 - val_acc: 0.6591\n",
            "Epoch 74/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0733 - acc: 0.7117 - val_loss: 1.3826 - val_acc: 0.6797\n",
            "Epoch 75/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0567 - acc: 0.7164 - val_loss: 1.4452 - val_acc: 0.6622\n",
            "Epoch 76/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.1227 - acc: 0.6978 - val_loss: 1.4552 - val_acc: 0.6715\n",
            "Epoch 77/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0830 - acc: 0.7052 - val_loss: 1.5203 - val_acc: 0.6581\n",
            "Epoch 78/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 1.0612 - acc: 0.7126 - val_loss: 1.4150 - val_acc: 0.6849\n",
            "Epoch 79/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0815 - acc: 0.7077 - val_loss: 1.3347 - val_acc: 0.6890\n",
            "Epoch 80/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.0574 - acc: 0.7119 - val_loss: 1.3984 - val_acc: 0.6849\n",
            "Epoch 81/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0307 - acc: 0.7221 - val_loss: 1.3253 - val_acc: 0.6828\n",
            "Epoch 82/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0392 - acc: 0.7154 - val_loss: 1.4646 - val_acc: 0.6725\n",
            "Epoch 83/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0400 - acc: 0.7171 - val_loss: 1.3549 - val_acc: 0.6735\n",
            "Epoch 84/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0084 - acc: 0.7268 - val_loss: 1.3756 - val_acc: 0.6869\n",
            "Epoch 85/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0629 - acc: 0.7156 - val_loss: 1.3383 - val_acc: 0.6859\n",
            "Epoch 86/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0625 - acc: 0.7123 - val_loss: 1.3757 - val_acc: 0.6952\n",
            "Epoch 87/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0417 - acc: 0.7176 - val_loss: 1.4252 - val_acc: 0.6777\n",
            "Epoch 88/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0433 - acc: 0.7143 - val_loss: 1.3903 - val_acc: 0.6849\n",
            "Epoch 89/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0097 - acc: 0.7266 - val_loss: 1.3983 - val_acc: 0.6910\n",
            "Epoch 90/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0276 - acc: 0.7210 - val_loss: 1.3344 - val_acc: 0.6982\n",
            "Epoch 91/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.0010 - acc: 0.7241 - val_loss: 1.4084 - val_acc: 0.6818\n",
            "Epoch 92/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0395 - acc: 0.7208 - val_loss: 1.4048 - val_acc: 0.6818\n",
            "Epoch 93/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 1.0083 - acc: 0.7279 - val_loss: 1.4072 - val_acc: 0.6900\n",
            "Epoch 94/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0284 - acc: 0.7185 - val_loss: 1.4550 - val_acc: 0.6849\n",
            "Epoch 95/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 1.0015 - acc: 0.7249 - val_loss: 1.2873 - val_acc: 0.6982\n",
            "Epoch 96/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 1.0407 - acc: 0.7159 - val_loss: 1.4104 - val_acc: 0.6787\n",
            "Epoch 97/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9809 - acc: 0.7290 - val_loss: 1.3854 - val_acc: 0.6684\n",
            "Epoch 98/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9905 - acc: 0.7270 - val_loss: 1.3352 - val_acc: 0.7055\n",
            "Epoch 99/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9835 - acc: 0.7282 - val_loss: 1.2845 - val_acc: 0.7055\n",
            "Epoch 100/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 0.9618 - acc: 0.7377 - val_loss: 1.3937 - val_acc: 0.6818\n",
            "Epoch 101/200\n",
            "8732/8732 [==============================] - 3s 354us/step - loss: 0.9996 - acc: 0.7288 - val_loss: 1.3665 - val_acc: 0.6838\n",
            "Epoch 102/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 1.0179 - acc: 0.7210 - val_loss: 1.3352 - val_acc: 0.6931\n",
            "Epoch 103/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9846 - acc: 0.7296 - val_loss: 1.3279 - val_acc: 0.6931\n",
            "Epoch 104/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9579 - acc: 0.7278 - val_loss: 1.3364 - val_acc: 0.6931\n",
            "Epoch 105/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9825 - acc: 0.7309 - val_loss: 1.3102 - val_acc: 0.6982\n",
            "Epoch 106/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9423 - acc: 0.7377 - val_loss: 1.6130 - val_acc: 0.6694\n",
            "Epoch 107/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 0.9513 - acc: 0.7380 - val_loss: 1.5193 - val_acc: 0.6880\n",
            "Epoch 108/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9686 - acc: 0.7334 - val_loss: 1.4042 - val_acc: 0.6869\n",
            "Epoch 109/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9636 - acc: 0.7337 - val_loss: 1.3747 - val_acc: 0.6849\n",
            "Epoch 110/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 0.9683 - acc: 0.7369 - val_loss: 1.3862 - val_acc: 0.6890\n",
            "Epoch 111/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9742 - acc: 0.7278 - val_loss: 1.4259 - val_acc: 0.6900\n",
            "Epoch 112/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9546 - acc: 0.7364 - val_loss: 1.3233 - val_acc: 0.7013\n",
            "Epoch 113/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9458 - acc: 0.7405 - val_loss: 1.3754 - val_acc: 0.6869\n",
            "Epoch 114/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9399 - acc: 0.7406 - val_loss: 1.3584 - val_acc: 0.6849\n",
            "Epoch 115/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9322 - acc: 0.7395 - val_loss: 1.4632 - val_acc: 0.6910\n",
            "Epoch 116/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9369 - acc: 0.7413 - val_loss: 1.3039 - val_acc: 0.7044\n",
            "Epoch 117/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9124 - acc: 0.7423 - val_loss: 1.3904 - val_acc: 0.7013\n",
            "Epoch 118/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9403 - acc: 0.7388 - val_loss: 1.3525 - val_acc: 0.7013\n",
            "Epoch 119/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.9560 - acc: 0.7431 - val_loss: 1.2824 - val_acc: 0.7075\n",
            "Epoch 120/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9413 - acc: 0.7385 - val_loss: 1.4123 - val_acc: 0.6931\n",
            "Epoch 121/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9474 - acc: 0.7369 - val_loss: 1.4164 - val_acc: 0.6993\n",
            "Epoch 122/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.9423 - acc: 0.7385 - val_loss: 1.3644 - val_acc: 0.6952\n",
            "Epoch 123/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9126 - acc: 0.7450 - val_loss: 1.3215 - val_acc: 0.7065\n",
            "Epoch 124/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9276 - acc: 0.7419 - val_loss: 1.4214 - val_acc: 0.7055\n",
            "Epoch 125/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 0.9303 - acc: 0.7442 - val_loss: 1.3217 - val_acc: 0.7055\n",
            "Epoch 126/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 0.9255 - acc: 0.7451 - val_loss: 1.4256 - val_acc: 0.6900\n",
            "Epoch 127/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8946 - acc: 0.7510 - val_loss: 1.4668 - val_acc: 0.6880\n",
            "Epoch 128/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9221 - acc: 0.7436 - val_loss: 1.3100 - val_acc: 0.7065\n",
            "Epoch 129/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8970 - acc: 0.7501 - val_loss: 1.4096 - val_acc: 0.6982\n",
            "Epoch 130/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8920 - acc: 0.7452 - val_loss: 1.4468 - val_acc: 0.6766\n",
            "Epoch 131/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9051 - acc: 0.7461 - val_loss: 1.3967 - val_acc: 0.6910\n",
            "Epoch 132/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9009 - acc: 0.7527 - val_loss: 1.4060 - val_acc: 0.7065\n",
            "Epoch 133/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9164 - acc: 0.7432 - val_loss: 1.6377 - val_acc: 0.6684\n",
            "Epoch 134/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 0.9011 - acc: 0.7473 - val_loss: 1.4123 - val_acc: 0.6962\n",
            "Epoch 135/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.9262 - acc: 0.7436 - val_loss: 1.3892 - val_acc: 0.6921\n",
            "Epoch 136/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 0.9087 - acc: 0.7460 - val_loss: 1.3283 - val_acc: 0.7024\n",
            "Epoch 137/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8705 - acc: 0.7584 - val_loss: 1.4173 - val_acc: 0.6952\n",
            "Epoch 138/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8743 - acc: 0.7547 - val_loss: 1.3316 - val_acc: 0.7137\n",
            "Epoch 139/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.9133 - acc: 0.7440 - val_loss: 1.3890 - val_acc: 0.7024\n",
            "Epoch 140/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8791 - acc: 0.7547 - val_loss: 1.3346 - val_acc: 0.6952\n",
            "Epoch 141/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9172 - acc: 0.7468 - val_loss: 1.4914 - val_acc: 0.6797\n",
            "Epoch 142/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8976 - acc: 0.7499 - val_loss: 1.3620 - val_acc: 0.6838\n",
            "Epoch 143/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8755 - acc: 0.7552 - val_loss: 1.4645 - val_acc: 0.6807\n",
            "Epoch 144/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8897 - acc: 0.7537 - val_loss: 1.4178 - val_acc: 0.6828\n",
            "Epoch 145/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8913 - acc: 0.7499 - val_loss: 1.4121 - val_acc: 0.7044\n",
            "Epoch 146/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8905 - acc: 0.7521 - val_loss: 1.3816 - val_acc: 0.6972\n",
            "Epoch 147/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8879 - acc: 0.7468 - val_loss: 1.4613 - val_acc: 0.7106\n",
            "Epoch 148/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8802 - acc: 0.7522 - val_loss: 1.2866 - val_acc: 0.7106\n",
            "Epoch 149/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8940 - acc: 0.7477 - val_loss: 1.4840 - val_acc: 0.6993\n",
            "Epoch 150/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8770 - acc: 0.7568 - val_loss: 1.3875 - val_acc: 0.6952\n",
            "Epoch 151/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8864 - acc: 0.7448 - val_loss: 1.4184 - val_acc: 0.6952\n",
            "Epoch 152/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8768 - acc: 0.7580 - val_loss: 1.3510 - val_acc: 0.6952\n",
            "Epoch 153/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8608 - acc: 0.7573 - val_loss: 1.4173 - val_acc: 0.7044\n",
            "Epoch 154/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8637 - acc: 0.7527 - val_loss: 1.3817 - val_acc: 0.7075\n",
            "Epoch 155/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8936 - acc: 0.7534 - val_loss: 1.3457 - val_acc: 0.7024\n",
            "Epoch 156/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.9141 - acc: 0.7442 - val_loss: 1.3865 - val_acc: 0.7034\n",
            "Epoch 157/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8491 - acc: 0.7574 - val_loss: 1.3719 - val_acc: 0.6952\n",
            "Epoch 158/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8613 - acc: 0.7582 - val_loss: 1.4051 - val_acc: 0.6931\n",
            "Epoch 159/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8593 - acc: 0.7549 - val_loss: 1.3826 - val_acc: 0.7096\n",
            "Epoch 160/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8633 - acc: 0.7595 - val_loss: 1.4037 - val_acc: 0.7003\n",
            "Epoch 161/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8638 - acc: 0.7571 - val_loss: 1.3918 - val_acc: 0.6972\n",
            "Epoch 162/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8250 - acc: 0.7671 - val_loss: 1.4632 - val_acc: 0.6993\n",
            "Epoch 163/200\n",
            "8732/8732 [==============================] - 3s 354us/step - loss: 0.8363 - acc: 0.7673 - val_loss: 1.3907 - val_acc: 0.7055\n",
            "Epoch 164/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8339 - acc: 0.7627 - val_loss: 1.4613 - val_acc: 0.6931\n",
            "Epoch 165/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8898 - acc: 0.7516 - val_loss: 1.3580 - val_acc: 0.7055\n",
            "Epoch 166/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8789 - acc: 0.7521 - val_loss: 1.4819 - val_acc: 0.7055\n",
            "Epoch 167/200\n",
            "8732/8732 [==============================] - 3s 360us/step - loss: 0.8391 - acc: 0.7592 - val_loss: 1.3490 - val_acc: 0.7096\n",
            "Epoch 168/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8356 - acc: 0.7617 - val_loss: 1.4820 - val_acc: 0.6972\n",
            "Epoch 169/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8411 - acc: 0.7601 - val_loss: 1.3919 - val_acc: 0.7003\n",
            "Epoch 170/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8140 - acc: 0.7687 - val_loss: 1.2791 - val_acc: 0.7085\n",
            "Epoch 171/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8498 - acc: 0.7613 - val_loss: 1.3866 - val_acc: 0.7034\n",
            "Epoch 172/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8321 - acc: 0.7621 - val_loss: 1.3589 - val_acc: 0.7044\n",
            "Epoch 173/200\n",
            "8732/8732 [==============================] - 3s 353us/step - loss: 0.8265 - acc: 0.7665 - val_loss: 1.3150 - val_acc: 0.7085\n",
            "Epoch 174/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.9112 - acc: 0.7503 - val_loss: 1.4145 - val_acc: 0.7055\n",
            "Epoch 175/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8559 - acc: 0.7600 - val_loss: 1.4838 - val_acc: 0.6859\n",
            "Epoch 176/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8350 - acc: 0.7635 - val_loss: 1.3015 - val_acc: 0.7065\n",
            "Epoch 177/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8529 - acc: 0.7639 - val_loss: 1.3576 - val_acc: 0.6972\n",
            "Epoch 178/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8388 - acc: 0.7629 - val_loss: 1.3193 - val_acc: 0.7003\n",
            "Epoch 179/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8549 - acc: 0.7601 - val_loss: 1.4661 - val_acc: 0.6941\n",
            "Epoch 180/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8192 - acc: 0.7678 - val_loss: 1.4847 - val_acc: 0.6952\n",
            "Epoch 181/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.7993 - acc: 0.7699 - val_loss: 1.3693 - val_acc: 0.7127\n",
            "Epoch 182/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8106 - acc: 0.7712 - val_loss: 1.4184 - val_acc: 0.7034\n",
            "Epoch 183/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8275 - acc: 0.7656 - val_loss: 1.3042 - val_acc: 0.7065\n",
            "Epoch 184/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8109 - acc: 0.7705 - val_loss: 1.4394 - val_acc: 0.6910\n",
            "Epoch 185/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8132 - acc: 0.7641 - val_loss: 1.4115 - val_acc: 0.6982\n",
            "Epoch 186/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8056 - acc: 0.7678 - val_loss: 1.3700 - val_acc: 0.7075\n",
            "Epoch 187/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8074 - acc: 0.7703 - val_loss: 1.4153 - val_acc: 0.7034\n",
            "Epoch 188/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.8244 - acc: 0.7671 - val_loss: 1.3981 - val_acc: 0.6900\n",
            "Epoch 189/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8132 - acc: 0.7696 - val_loss: 1.3765 - val_acc: 0.7065\n",
            "Epoch 190/200\n",
            "8732/8732 [==============================] - 3s 356us/step - loss: 0.7919 - acc: 0.7735 - val_loss: 1.4027 - val_acc: 0.7127\n",
            "Epoch 191/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8067 - acc: 0.7676 - val_loss: 1.4594 - val_acc: 0.6952\n",
            "Epoch 192/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.7786 - acc: 0.7739 - val_loss: 1.3245 - val_acc: 0.7065\n",
            "Epoch 193/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.7836 - acc: 0.7746 - val_loss: 1.4687 - val_acc: 0.7106\n",
            "Epoch 194/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.7974 - acc: 0.7692 - val_loss: 1.4431 - val_acc: 0.6982\n",
            "Epoch 195/200\n",
            "8732/8732 [==============================] - 3s 359us/step - loss: 0.8504 - acc: 0.7602 - val_loss: 1.3876 - val_acc: 0.6952\n",
            "Epoch 196/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8015 - acc: 0.7746 - val_loss: 1.4279 - val_acc: 0.6931\n",
            "Epoch 197/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.7881 - acc: 0.7722 - val_loss: 1.4026 - val_acc: 0.7013\n",
            "Epoch 198/200\n",
            "8732/8732 [==============================] - 3s 358us/step - loss: 0.8124 - acc: 0.7704 - val_loss: 1.4610 - val_acc: 0.6982\n",
            "Epoch 199/200\n",
            "8732/8732 [==============================] - 3s 355us/step - loss: 0.7939 - acc: 0.7738 - val_loss: 1.4634 - val_acc: 0.6859\n",
            "Epoch 200/200\n",
            "8732/8732 [==============================] - 3s 357us/step - loss: 0.8286 - acc: 0.7625 - val_loss: 1.4631 - val_acc: 0.7106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd8dxnCzExd1xHCcL+f++PHLmcCcAqgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAD6dQa3GfiP",
        "colab_type": "text"
      },
      "source": [
        "###Save Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knjT7nY8GfA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('urban_sound.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyRRiwEGGddg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQYm890ntf12",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Zl4IuyPrM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(history.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAufMuSHEWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXTfd8MKHoYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm5FlvfX88wo",
        "colab_type": "text"
      },
      "source": [
        "##Alternate folder train and test structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9njsm5MskSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = wav2mfcc('/content/small-urban-sound-dataset/tiny-dataset/crackling_fire/1-17150-A.wav')\n",
        "\n",
        "#X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARF4iPLZXH7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sample.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7phdcHrqXCat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_reshape = sample.reshape(sample(10,51,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5xmQdSWFBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(get_labels() [0] [np.argmax(model.predict(sample_reshape))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiLUN--y0u79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBULmNeFteL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "base_directory ='/content/target_dataset/'\n",
        "os.mkdir(base_directory)\n",
        "train_dir = os.path.join(base_directory, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_directory, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_directory, 'test')\n",
        "os.mkdir(test_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDMMKPgkXSko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dataset_dir = '/content/Sound-Datasets/combined_datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcURx0euURiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gunshot_dir = os.path.join(train_dir, 'gun_shot')\n",
        "os.mkdir(train_gunshot_dir)\n",
        "train_dogbark_dir = os.path.join(train_dir, 'dog_bark')\n",
        "os.mkdir(train_dogbark_dir)\n",
        "\n",
        "validation_gunshot_dir = os.path.join(validation_dir, 'gun_shot')\n",
        "os.mkdir(validation_gunshot_dir)\n",
        "validation_dogbark_dir = os.path.join(validation_dir, 'dog_bark')\n",
        "os.mkdir(validation_dogbark_dir)\n",
        "\n",
        "test_gunshot_dir = os.path.join(test_dir, 'gun_shot')\n",
        "os.mkdir(test_gunshot_dir)\n",
        "test_dogbark_dir = os.path.join(test_dir, 'dog_bark')\n",
        "os.mkdir(test_dogbark_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-fuVCQZWWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames_dog = os.listdir('/content/Sound-Datasets/combined_datasets/dog_bark')\n",
        "fnames_gun = os.listdir('/content/Sound-Datasets/combined_datasets/gun_shot')\n",
        "fnames = os.listdir('/content/Sound-Datasets/combined_datasets/dog_bark')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54t8veJLZdw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(fnames)\n",
        "size = len(fnames)\n",
        "train_percentage = 0.8\n",
        "validation_percentage = 0.1\n",
        "test_percentage = 0.1\n",
        "print('train percentage = %f' %train_percentage)\n",
        "train_size = int(round(size * (train_percentage)))\n",
        "validation_size = int(round(size * (validation_percentage)))\n",
        "test_size = int(round(size * (test_percentage)))\n",
        "print(size)\n",
        "print('train_size = %i' %train_size)\n",
        "print('validation_size = %i' %validation_size)\n",
        "print('test_size = %i' %test_size)\n",
        "total = train_size + validation_size + test_size\n",
        "print(total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pojp7QvbfKch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#os.chdir('/content/combined_datasets/dog_bark')\n",
        "train_list=[]\n",
        "validation_list=[]\n",
        "test_list=[]\n",
        "\n",
        "train_list = fnames[0:train_size]\n",
        "validation_list = fnames[train_size:train_size+validation_size]\n",
        "test_list = fnames[train_size+validation_size:total]\n",
        "\n",
        "\n",
        "for train in train_list:\n",
        "  src_train = os.path.join(original_dataset_dir+'dog_bark', train )\n",
        "  dst_train = os.path.join('/content/target_dataset/train/dog_bark', train)\n",
        "  shutil.copyfile(src_train, dst_train)\n",
        "\n",
        "for validation in validation_list:\n",
        "  src_validation = os.path.join(original_dataset_dir+'dog_bark', validation)\n",
        "  dst_validation = os.path.join('/content/target_dataset/validation/dog_bark', validation)\n",
        "  shutil.copyfile(src_validation, dst_validation)\n",
        "  \n",
        "for test in test_list:\n",
        "  src_test = os.path.join(original_dataset_dir+'dog_bark', test)\n",
        "  dst_test = os.path.join('/content/target_dataset/test/dog_bark', test)\n",
        "  shutil.copyfile(src_test, dst_test)\n",
        "  \n",
        "        \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOB0kg2_DGCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames_train = os.listdir('/content/target_dataset/train/dog_bark')\n",
        "print(len(fnames_train))\n",
        "fnames_val = os.listdir('/content/target_dataset/validation/dog_bark')\n",
        "print(len(fnames_val))\n",
        "fnames_test = os.listdir('/content/target_dataset/test/dog_bark')\n",
        "print(len(fnames_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z94KvPBWU6kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_gunshot_dir = os.path.join(validation_dir, 'gun_shot')\n",
        "os.mkdir(validation_gunshot_dir)\n",
        "validation_dogbark_dir = os.path.join(validation_dir, 'dog_bark')\n",
        "os.mkdir(validation_dogbark_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imuKEMG8U8Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gunshot_dir = os.path.join(test_dir, 'gun_shot')\n",
        "os.mkdir(test_gunshot_dir)\n",
        "test_dogbark_dir = os.path.join(test_dir, 'dog_bark')\n",
        "os.mkdir(test_dogbark_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywdXdFQFRUXu",
        "colab_type": "text"
      },
      "source": [
        "###Preparing for google speech dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdio_TpuAE5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url='http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
        "os.makedirs(dest_directory)\n",
        "filename = data_url.split('/')[-1]\n",
        "filepath = os.path.join(dest_directory, filename)\n",
        "\n",
        "print(filename)\n",
        "print(filepath)\n",
        " \n",
        "def _progress(count, block_size, total_size):\n",
        "    sys.stdout.write('\\r>> Downloading %s %.1f%%' % \\\n",
        "            (filename, float(count * block_size) / float(total_size) * 100.0)) \n",
        "    sys.stdout.flush()\n",
        "\n",
        "urban_dataset_dir = '/content/combined_datasets/' \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z1f7OCcESAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
        "statinfo = os.stat(filepath)\n",
        "tf.logging.info('Successfully downloaded %s (%d bytes)', filename, statinfo.st_size)\n",
        "tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}