{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villasen/colab_notebooks/blob/master/Keras_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfXFsAnRkn9",
        "colab_type": "text"
      },
      "source": [
        "#Urban dataset download and file structure setup for train, validation, and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mpdiRj4-Fs",
        "colab_type": "code",
        "outputId": "9ffdbe47-2c03-4f53-9bb2-c96e6bb5b3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/villasen/small-urban-sound-dataset.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'small-urban-sound-dataset'...\n",
            "remote: Enumerating objects: 9719, done.\u001b[K\n",
            "remote: Counting objects: 100% (9719/9719), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9324/9324), done.\u001b[K\n",
            "remote: Total 9719 (delta 398), reused 9713 (delta 394), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9719/9719), 259.08 MiB | 37.24 MiB/s, done.\n",
            "Resolving deltas: 100% (398/398), done.\n",
            "Checking out files: 100% (10185/10185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qrPrM21WXMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/small-urban-sound-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpCKSN5YBPkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r test_single_file/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD6xOVD6ho2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a03c39b-cf65-444c-9924-0c08c1fd897a"
      },
      "source": [
        "!rm -r /content/target_npy_files/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/target_npy_files/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz67Mm9GIUy",
        "colab_type": "code",
        "outputId": "94337439-9dd9-4a1a-e1b4-ca1a0ef4c169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        }
      },
      "source": [
        "#from preprocess import *\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow\n",
        "import scipy\n",
        "import os, shutil\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "target_dir = '/content/target_npy_files'\n",
        "target_model = '/content/target_model/'\n",
        "#DATA_PATH = \"small-urban-sound-dataset/tiny-dataset/\"\n",
        "DATA_PATH = \"small-urban-sound-dataset/combined_datasets/\"\n",
        "os.mkdir(target_dir)\n",
        "\n",
        "test_single_file = 'test_single_file/'\n",
        "os.mkdir(test_single_file)\n",
        "!mv small-urban-sound-dataset/combined_datasets/Helicopter/1-172649-A.wav test_single_file\n",
        "\n",
        "\n",
        "def wav2mfcc(file_path, max_pad_len):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=10, n_fft=640, hop_length=320)\n",
        "    pad_width = max_pad_len - mfcc.shape[1]\n",
        "    if pad_width < 0: \n",
        "      print(mfcc.shape[1])\n",
        "      print(pad_width)\n",
        "      print(\"error in \"+ file_path)\n",
        "    \n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    return mfcc\n",
        "\n",
        "  \n",
        "  \n",
        "def get_labels(path):\n",
        "    labels = os.listdir(path) \n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices, to_categorical(label_indices)  \n",
        "\n",
        "\n",
        "\n",
        "               \n",
        "def save_data_to_array(path=DATA_PATH, max_pad_len=51):\n",
        "    labels, _, _ = get_labels(path)\n",
        "\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        mfcc_vectors = []\n",
        "\n",
        "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "        for wavfile in wavfiles:\n",
        "            if label == '_background_noise_' : break\n",
        "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
        "            \n",
        "            mfcc_vectors.append(mfcc)\n",
        "        np.save('/content/target_npy_files/' + label + '.npy', mfcc_vectors)\n",
        "        print(label)\n",
        "        print(len(mfcc_vectors))\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "def get_train_test(split_ratio=0.9, random_state=42):\n",
        "    # Get available labels\n",
        "    labels, indices, _ = get_labels(DATA_PATH)\n",
        "\n",
        "    # Getting first arrays\n",
        "    X = np.load('/content/target_npy_files/' + labels[0] + '.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    \n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load('/content/target_npy_files/' + label + '.npy')\n",
        "        \n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "        \n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "save_data_to_array(path=DATA_PATH, max_pad_len=51)    \n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 10, 51, 1)\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hen\n",
            "40\n",
            "dog_bark\n",
            "1000\n",
            "coughing\n",
            "40\n",
            "cow\n",
            "40\n",
            "pig\n",
            "40\n",
            "train\n",
            "40\n",
            "street_music\n",
            "1000\n",
            "clapping\n",
            "40\n",
            "air_conditioner\n",
            "1000\n",
            "sea_waves\n",
            "40\n",
            "chirping_birds\n",
            "40\n",
            "laughing\n",
            "40\n",
            "chainsaw\n",
            "40\n",
            "siren\n",
            "929\n",
            "pouring_water\n",
            "40\n",
            "water_drops\n",
            "40\n",
            "jackhammer\n",
            "1000\n",
            "clock_tick\n",
            "40\n",
            "insects\n",
            "40\n",
            "thunderstorm\n",
            "40\n",
            "cat\n",
            "40\n",
            "toilet_flush\n",
            "40\n",
            "drilling\n",
            "1000\n",
            "wind\n",
            "40\n",
            "clock_alarm\n",
            "40\n",
            "engine_idling\n",
            "1000\n",
            "mouse_click\n",
            "40\n",
            "car_horn\n",
            "40\n",
            "breathing\n",
            "40\n",
            "children_playing\n",
            "1000\n",
            "sneezing\n",
            "40\n",
            "church_bells\n",
            "40\n",
            "washing_machine\n",
            "40\n",
            "rain\n",
            "40\n",
            "rooster\n",
            "40\n",
            "can_opening\n",
            "40\n",
            "vacuum_cleaner\n",
            "40\n",
            "brushing_teeth\n",
            "40\n",
            "snoring\n",
            "40\n",
            "Helicopter\n",
            "39\n",
            "gun_shot\n",
            "374\n",
            "airplane\n",
            "40\n",
            "sheep\n",
            "40\n",
            "keyboard_typing\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi_wRLjZgBWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "#save_data_to_array(path=DATA_PATH, max_pad_len=51)    \n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 10, 51, 1)\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvG5N6W6MRLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/target_npy_files/*.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWZNjHYTtLnS",
        "colab_type": "text"
      },
      "source": [
        "# Building DS-CNN model using Keras framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWsjPl-K0IE4",
        "colab_type": "code",
        "outputId": "a2b132d2-3cac-4e94-d47a-4cc029b726d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7535
        }
      },
      "source": [
        "# Creating Keras sequential model\n",
        "#bn = 1\n",
        "target_model = '/content/target_model/'\n",
        "os.mkdir(target_model)\n",
        "BN=True\n",
        "model = models.Sequential()\n",
        "\n",
        "def dscnn_train():\n",
        "  # 1\n",
        "      model.add(layers.Conv2D(64, (4,10), strides=(2,2), padding='same', activation='relu', \\\n",
        "                #input_shape=(10, 49, 1)))\n",
        "                input_shape=(10,51,1)))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                                center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                                gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                                moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                                gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      # 2\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))  \n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      # 3\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      \n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "      # 4\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "      # 5\n",
        "      model.add(layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu'))\n",
        "      if BN == True:\n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False))\n",
        "      if BN == True:      \n",
        "          model.add(layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, \\\n",
        "                                              center=True, scale=True, beta_initializer='zeros', \\\n",
        "                                              gamma_initializer='ones', moving_mean_initializer='zeros', \\\n",
        "                                              moving_variance_initializer='ones', beta_regularizer=None, \\\n",
        "                                              gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "      \n",
        "           \n",
        "      \n",
        "# Final layer\n",
        "      \n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.AveragePooling2D(pool_size=(5, 25), strides=(2,2), padding='valid', data_format=None))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Flatten(data_format=None))\n",
        "     # model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Dense(64, activation='relu'))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      #model.add(layers.Dense(12, activation='softmax'))\n",
        "      model.add(layers.Dense(44, activation='softmax'))\n",
        "      #model.add(layers.Dropout(0.5))\n",
        "      # Compilation step to choose loss function, optimizer and metric\n",
        "      # Configuring the learning process\n",
        "      model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "      #model.fit()\n",
        "      history = model.fit(X_train, y_train_hot, batch_size=100, epochs=200, verbose=1, validation_data=(X_test, y_test_hot))\n",
        "      \n",
        "      #plt.plot(history.history['acc'])\n",
        "      #Restarts layer sequence number \n",
        "      #K.clear_session()\n",
        "\n",
        "      acc = history.history['acc']\n",
        "      val_acc = history.history['val_acc']\n",
        "      loss = history.history['loss']\n",
        "      val_loss = history.history['val_loss']\n",
        "      epochs = range(1, len(acc) + 1)\n",
        "      \n",
        "      plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "      plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "      plt.title('Training and validation accuracy')\n",
        "      plt.legend()\n",
        "\n",
        "      plt.figure()\n",
        "\n",
        "      plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "      plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
        "      plt.title('Training and validation loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "      \n",
        "      \n",
        "      model.save('/content/target_model/urban_sound.h5')\n",
        "  \n",
        "dscnn_train()  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 8731 samples, validate on 971 samples\n",
            "Epoch 1/200\n",
            "8731/8731 [==============================] - 7s 792us/step - loss: 3.1998 - acc: 0.1160 - val_loss: 2.8840 - val_acc: 0.1287\n",
            "Epoch 2/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 2.6929 - acc: 0.1833 - val_loss: 2.8833 - val_acc: 0.1390\n",
            "Epoch 3/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 2.5627 - acc: 0.2180 - val_loss: 2.6976 - val_acc: 0.2019\n",
            "Epoch 4/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 2.4785 - acc: 0.2405 - val_loss: 2.5780 - val_acc: 0.2441\n",
            "Epoch 5/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 2.3919 - acc: 0.2621 - val_loss: 2.3819 - val_acc: 0.2966\n",
            "Epoch 6/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 2.3020 - acc: 0.2949 - val_loss: 2.4921 - val_acc: 0.2533\n",
            "Epoch 7/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 2.2439 - acc: 0.3169 - val_loss: 2.2577 - val_acc: 0.3131\n",
            "Epoch 8/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 2.1697 - acc: 0.3382 - val_loss: 2.2891 - val_acc: 0.3306\n",
            "Epoch 9/200\n",
            "8731/8731 [==============================] - 2s 195us/step - loss: 2.1374 - acc: 0.3543 - val_loss: 2.1853 - val_acc: 0.3831\n",
            "Epoch 10/200\n",
            "8731/8731 [==============================] - 2s 196us/step - loss: 2.0812 - acc: 0.3664 - val_loss: 2.3724 - val_acc: 0.2925\n",
            "Epoch 11/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 2.0435 - acc: 0.3899 - val_loss: 2.0187 - val_acc: 0.3996\n",
            "Epoch 12/200\n",
            "8731/8731 [==============================] - 2s 177us/step - loss: 1.9933 - acc: 0.4146 - val_loss: 2.0200 - val_acc: 0.3975\n",
            "Epoch 13/200\n",
            "8731/8731 [==============================] - 2s 177us/step - loss: 1.9523 - acc: 0.4253 - val_loss: 1.9649 - val_acc: 0.4367\n",
            "Epoch 14/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 1.8864 - acc: 0.4427 - val_loss: 1.8960 - val_acc: 0.4418\n",
            "Epoch 15/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 1.8547 - acc: 0.4619 - val_loss: 2.1299 - val_acc: 0.4078\n",
            "Epoch 16/200\n",
            "8731/8731 [==============================] - 2s 176us/step - loss: 1.8319 - acc: 0.4660 - val_loss: 1.9767 - val_acc: 0.4284\n",
            "Epoch 17/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.7879 - acc: 0.4886 - val_loss: 1.7976 - val_acc: 0.4799\n",
            "Epoch 18/200\n",
            "8731/8731 [==============================] - 2s 178us/step - loss: 1.7574 - acc: 0.4908 - val_loss: 1.8022 - val_acc: 0.4737\n",
            "Epoch 19/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.7207 - acc: 0.5045 - val_loss: 1.8030 - val_acc: 0.5015\n",
            "Epoch 20/200\n",
            "8731/8731 [==============================] - 2s 176us/step - loss: 1.6953 - acc: 0.5169 - val_loss: 1.7588 - val_acc: 0.5036\n",
            "Epoch 21/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 1.6746 - acc: 0.5194 - val_loss: 1.7512 - val_acc: 0.5088\n",
            "Epoch 22/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.6284 - acc: 0.5357 - val_loss: 1.7209 - val_acc: 0.5232\n",
            "Epoch 23/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.6267 - acc: 0.5391 - val_loss: 1.7054 - val_acc: 0.5273\n",
            "Epoch 24/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.5771 - acc: 0.5474 - val_loss: 1.7156 - val_acc: 0.5314\n",
            "Epoch 25/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 1.5655 - acc: 0.5518 - val_loss: 1.7105 - val_acc: 0.5263\n",
            "Epoch 26/200\n",
            "8731/8731 [==============================] - 2s 178us/step - loss: 1.5391 - acc: 0.5672 - val_loss: 1.6434 - val_acc: 0.5541\n",
            "Epoch 27/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.5280 - acc: 0.5704 - val_loss: 1.6493 - val_acc: 0.5685\n",
            "Epoch 28/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.4891 - acc: 0.5747 - val_loss: 1.6627 - val_acc: 0.5582\n",
            "Epoch 29/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.4838 - acc: 0.5871 - val_loss: 1.6282 - val_acc: 0.5685\n",
            "Epoch 30/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.4840 - acc: 0.5940 - val_loss: 1.7638 - val_acc: 0.5376\n",
            "Epoch 31/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.4581 - acc: 0.5956 - val_loss: 1.6412 - val_acc: 0.5654\n",
            "Epoch 32/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.4336 - acc: 0.6082 - val_loss: 1.5718 - val_acc: 0.5602\n",
            "Epoch 33/200\n",
            "8731/8731 [==============================] - 2s 178us/step - loss: 1.4246 - acc: 0.6086 - val_loss: 1.5806 - val_acc: 0.5716\n",
            "Epoch 34/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.4047 - acc: 0.6114 - val_loss: 1.7642 - val_acc: 0.5499\n",
            "Epoch 35/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.3806 - acc: 0.6207 - val_loss: 1.6722 - val_acc: 0.5747\n",
            "Epoch 36/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.3787 - acc: 0.6224 - val_loss: 1.5398 - val_acc: 0.6148\n",
            "Epoch 37/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.3659 - acc: 0.6288 - val_loss: 1.6346 - val_acc: 0.5705\n",
            "Epoch 38/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.3502 - acc: 0.6331 - val_loss: 1.6542 - val_acc: 0.5685\n",
            "Epoch 39/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.3203 - acc: 0.6410 - val_loss: 1.5269 - val_acc: 0.5973\n",
            "Epoch 40/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 1.3183 - acc: 0.6417 - val_loss: 1.5322 - val_acc: 0.6272\n",
            "Epoch 41/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 1.3150 - acc: 0.6406 - val_loss: 1.4834 - val_acc: 0.6169\n",
            "Epoch 42/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 1.3090 - acc: 0.6504 - val_loss: 1.5257 - val_acc: 0.6014\n",
            "Epoch 43/200\n",
            "8731/8731 [==============================] - 2s 195us/step - loss: 1.2971 - acc: 0.6524 - val_loss: 1.6327 - val_acc: 0.5994\n",
            "Epoch 44/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 1.3071 - acc: 0.6561 - val_loss: 1.4219 - val_acc: 0.6395\n",
            "Epoch 45/200\n",
            "8731/8731 [==============================] - 2s 195us/step - loss: 1.2745 - acc: 0.6528 - val_loss: 1.4837 - val_acc: 0.6313\n",
            "Epoch 46/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 1.2647 - acc: 0.6582 - val_loss: 1.5521 - val_acc: 0.5911\n",
            "Epoch 47/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 1.2530 - acc: 0.6594 - val_loss: 1.5205 - val_acc: 0.6251\n",
            "Epoch 48/200\n",
            "8731/8731 [==============================] - 2s 190us/step - loss: 1.2319 - acc: 0.6683 - val_loss: 1.5902 - val_acc: 0.6148\n",
            "Epoch 49/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 1.2198 - acc: 0.6712 - val_loss: 1.4927 - val_acc: 0.6385\n",
            "Epoch 50/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.2219 - acc: 0.6708 - val_loss: 1.5171 - val_acc: 0.6282\n",
            "Epoch 51/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 1.2226 - acc: 0.6708 - val_loss: 1.4298 - val_acc: 0.6529\n",
            "Epoch 52/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.1968 - acc: 0.6750 - val_loss: 1.4930 - val_acc: 0.6354\n",
            "Epoch 53/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.2027 - acc: 0.6776 - val_loss: 1.5919 - val_acc: 0.6231\n",
            "Epoch 54/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 1.2009 - acc: 0.6767 - val_loss: 1.3893 - val_acc: 0.6426\n",
            "Epoch 55/200\n",
            "8731/8731 [==============================] - 2s 197us/step - loss: 1.2005 - acc: 0.6754 - val_loss: 1.5515 - val_acc: 0.6210\n",
            "Epoch 56/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 1.1636 - acc: 0.6847 - val_loss: 1.6309 - val_acc: 0.6169\n",
            "Epoch 57/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.1619 - acc: 0.6871 - val_loss: 1.5164 - val_acc: 0.6344\n",
            "Epoch 58/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.1699 - acc: 0.6806 - val_loss: 1.4618 - val_acc: 0.6426\n",
            "Epoch 59/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.1495 - acc: 0.6893 - val_loss: 1.5188 - val_acc: 0.6457\n",
            "Epoch 60/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.1801 - acc: 0.6850 - val_loss: 1.4301 - val_acc: 0.6303\n",
            "Epoch 61/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.1233 - acc: 0.6945 - val_loss: 1.4405 - val_acc: 0.6406\n",
            "Epoch 62/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.1400 - acc: 0.6872 - val_loss: 1.4302 - val_acc: 0.6457\n",
            "Epoch 63/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.1355 - acc: 0.6916 - val_loss: 1.4113 - val_acc: 0.6519\n",
            "Epoch 64/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.1504 - acc: 0.6934 - val_loss: 1.3886 - val_acc: 0.6447\n",
            "Epoch 65/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 1.1223 - acc: 0.6948 - val_loss: 1.4957 - val_acc: 0.6591\n",
            "Epoch 66/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.1340 - acc: 0.6952 - val_loss: 1.4286 - val_acc: 0.6560\n",
            "Epoch 67/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 1.0953 - acc: 0.7035 - val_loss: 1.3980 - val_acc: 0.6571\n",
            "Epoch 68/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 1.1151 - acc: 0.7014 - val_loss: 1.6307 - val_acc: 0.6189\n",
            "Epoch 69/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 1.1016 - acc: 0.7027 - val_loss: 1.3816 - val_acc: 0.6601\n",
            "Epoch 70/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.1013 - acc: 0.7008 - val_loss: 1.4750 - val_acc: 0.6540\n",
            "Epoch 71/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.1142 - acc: 0.6941 - val_loss: 1.4595 - val_acc: 0.6529\n",
            "Epoch 72/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.0719 - acc: 0.7031 - val_loss: 1.5075 - val_acc: 0.6426\n",
            "Epoch 73/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.0810 - acc: 0.7039 - val_loss: 1.4350 - val_acc: 0.6663\n",
            "Epoch 74/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.0665 - acc: 0.7070 - val_loss: 1.4921 - val_acc: 0.6643\n",
            "Epoch 75/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 1.0777 - acc: 0.7058 - val_loss: 1.4826 - val_acc: 0.6519\n",
            "Epoch 76/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.0642 - acc: 0.7152 - val_loss: 1.4043 - val_acc: 0.6571\n",
            "Epoch 77/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 1.0759 - acc: 0.7013 - val_loss: 1.4516 - val_acc: 0.6560\n",
            "Epoch 78/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.0548 - acc: 0.7105 - val_loss: 1.4502 - val_acc: 0.6601\n",
            "Epoch 79/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 1.0422 - acc: 0.7129 - val_loss: 1.5191 - val_acc: 0.6488\n",
            "Epoch 80/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 1.0454 - acc: 0.7131 - val_loss: 1.4632 - val_acc: 0.6457\n",
            "Epoch 81/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 1.0626 - acc: 0.7090 - val_loss: 1.3725 - val_acc: 0.6612\n",
            "Epoch 82/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 1.0407 - acc: 0.7138 - val_loss: 1.4256 - val_acc: 0.6550\n",
            "Epoch 83/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 1.0308 - acc: 0.7203 - val_loss: 1.4807 - val_acc: 0.6519\n",
            "Epoch 84/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 1.0523 - acc: 0.7098 - val_loss: 1.4861 - val_acc: 0.6571\n",
            "Epoch 85/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 1.0286 - acc: 0.7186 - val_loss: 1.5429 - val_acc: 0.6468\n",
            "Epoch 86/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 1.0581 - acc: 0.7081 - val_loss: 1.3742 - val_acc: 0.6488\n",
            "Epoch 87/200\n",
            "8731/8731 [==============================] - 2s 208us/step - loss: 1.0398 - acc: 0.7114 - val_loss: 1.3848 - val_acc: 0.6777\n",
            "Epoch 88/200\n",
            "8731/8731 [==============================] - 2s 202us/step - loss: 1.0125 - acc: 0.7204 - val_loss: 1.5260 - val_acc: 0.6550\n",
            "Epoch 89/200\n",
            "8731/8731 [==============================] - 2s 203us/step - loss: 1.0104 - acc: 0.7229 - val_loss: 1.5174 - val_acc: 0.6447\n",
            "Epoch 90/200\n",
            "8731/8731 [==============================] - 2s 197us/step - loss: 1.0171 - acc: 0.7233 - val_loss: 1.4135 - val_acc: 0.6622\n",
            "Epoch 91/200\n",
            "8731/8731 [==============================] - 2s 202us/step - loss: 1.0277 - acc: 0.7216 - val_loss: 1.3977 - val_acc: 0.6632\n",
            "Epoch 92/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 1.0185 - acc: 0.7207 - val_loss: 1.4804 - val_acc: 0.6643\n",
            "Epoch 93/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.9861 - acc: 0.7221 - val_loss: 1.4299 - val_acc: 0.6643\n",
            "Epoch 94/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 0.9786 - acc: 0.7300 - val_loss: 1.4989 - val_acc: 0.6663\n",
            "Epoch 95/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.9963 - acc: 0.7242 - val_loss: 1.4943 - val_acc: 0.6509\n",
            "Epoch 96/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 0.9916 - acc: 0.7306 - val_loss: 1.4865 - val_acc: 0.6447\n",
            "Epoch 97/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 0.9901 - acc: 0.7231 - val_loss: 1.4852 - val_acc: 0.6591\n",
            "Epoch 98/200\n",
            "8731/8731 [==============================] - 2s 178us/step - loss: 0.9947 - acc: 0.7256 - val_loss: 1.4273 - val_acc: 0.6704\n",
            "Epoch 99/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 0.9932 - acc: 0.7299 - val_loss: 1.4668 - val_acc: 0.6643\n",
            "Epoch 100/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 0.9712 - acc: 0.7361 - val_loss: 1.4265 - val_acc: 0.6725\n",
            "Epoch 101/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 0.9658 - acc: 0.7332 - val_loss: 1.4622 - val_acc: 0.6643\n",
            "Epoch 102/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 0.9691 - acc: 0.7319 - val_loss: 1.3759 - val_acc: 0.6838\n",
            "Epoch 103/200\n",
            "8731/8731 [==============================] - 2s 177us/step - loss: 0.9659 - acc: 0.7290 - val_loss: 1.4587 - val_acc: 0.6715\n",
            "Epoch 104/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 0.9798 - acc: 0.7332 - val_loss: 1.4394 - val_acc: 0.6601\n",
            "Epoch 105/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.9644 - acc: 0.7342 - val_loss: 1.5011 - val_acc: 0.6581\n",
            "Epoch 106/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 0.9555 - acc: 0.7365 - val_loss: 1.5608 - val_acc: 0.6622\n",
            "Epoch 107/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 0.9749 - acc: 0.7374 - val_loss: 1.4277 - val_acc: 0.6777\n",
            "Epoch 108/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.9506 - acc: 0.7385 - val_loss: 1.5193 - val_acc: 0.6715\n",
            "Epoch 109/200\n",
            "8731/8731 [==============================] - 2s 180us/step - loss: 0.9567 - acc: 0.7351 - val_loss: 1.4405 - val_acc: 0.6663\n",
            "Epoch 110/200\n",
            "8731/8731 [==============================] - 2s 179us/step - loss: 0.9524 - acc: 0.7371 - val_loss: 1.3765 - val_acc: 0.6777\n",
            "Epoch 111/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.9513 - acc: 0.7365 - val_loss: 1.4976 - val_acc: 0.6550\n",
            "Epoch 112/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9328 - acc: 0.7422 - val_loss: 1.4730 - val_acc: 0.6571\n",
            "Epoch 113/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.9465 - acc: 0.7350 - val_loss: 1.4988 - val_acc: 0.6704\n",
            "Epoch 114/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9261 - acc: 0.7413 - val_loss: 1.4209 - val_acc: 0.6694\n",
            "Epoch 115/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9696 - acc: 0.7336 - val_loss: 1.4332 - val_acc: 0.6715\n",
            "Epoch 116/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.9335 - acc: 0.7429 - val_loss: 1.6617 - val_acc: 0.6622\n",
            "Epoch 117/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9236 - acc: 0.7416 - val_loss: 1.5196 - val_acc: 0.6756\n",
            "Epoch 118/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.9675 - acc: 0.7345 - val_loss: 1.4618 - val_acc: 0.6694\n",
            "Epoch 119/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.9181 - acc: 0.7461 - val_loss: 1.4843 - val_acc: 0.6704\n",
            "Epoch 120/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9071 - acc: 0.7477 - val_loss: 1.4237 - val_acc: 0.6756\n",
            "Epoch 121/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9021 - acc: 0.7486 - val_loss: 1.4682 - val_acc: 0.6684\n",
            "Epoch 122/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.9593 - acc: 0.7375 - val_loss: 1.4271 - val_acc: 0.6735\n",
            "Epoch 123/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.9393 - acc: 0.7395 - val_loss: 1.4345 - val_acc: 0.6828\n",
            "Epoch 124/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.9357 - acc: 0.7401 - val_loss: 1.5150 - val_acc: 0.6704\n",
            "Epoch 125/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.8995 - acc: 0.7515 - val_loss: 1.4579 - val_acc: 0.6869\n",
            "Epoch 126/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.8892 - acc: 0.7485 - val_loss: 1.5462 - val_acc: 0.6807\n",
            "Epoch 127/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.9123 - acc: 0.7507 - val_loss: 1.4741 - val_acc: 0.6828\n",
            "Epoch 128/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.9012 - acc: 0.7488 - val_loss: 1.4709 - val_acc: 0.6601\n",
            "Epoch 129/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.8994 - acc: 0.7541 - val_loss: 1.4116 - val_acc: 0.6746\n",
            "Epoch 130/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 0.9022 - acc: 0.7478 - val_loss: 1.4199 - val_acc: 0.6746\n",
            "Epoch 131/200\n",
            "8731/8731 [==============================] - 2s 199us/step - loss: 0.9718 - acc: 0.7360 - val_loss: 1.4007 - val_acc: 0.6787\n",
            "Epoch 132/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 0.9197 - acc: 0.7457 - val_loss: 1.5596 - val_acc: 0.6437\n",
            "Epoch 133/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8785 - acc: 0.7520 - val_loss: 1.4608 - val_acc: 0.6756\n",
            "Epoch 134/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.8912 - acc: 0.7480 - val_loss: 1.4300 - val_acc: 0.6807\n",
            "Epoch 135/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 0.9126 - acc: 0.7462 - val_loss: 1.4277 - val_acc: 0.6828\n",
            "Epoch 136/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 0.8986 - acc: 0.7475 - val_loss: 1.4219 - val_acc: 0.6828\n",
            "Epoch 137/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.9008 - acc: 0.7454 - val_loss: 1.3216 - val_acc: 0.6838\n",
            "Epoch 138/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.8782 - acc: 0.7583 - val_loss: 1.4896 - val_acc: 0.6859\n",
            "Epoch 139/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.8726 - acc: 0.7548 - val_loss: 1.3696 - val_acc: 0.6859\n",
            "Epoch 140/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.8844 - acc: 0.7565 - val_loss: 1.4258 - val_acc: 0.6849\n",
            "Epoch 141/200\n",
            "8731/8731 [==============================] - 2s 196us/step - loss: 0.8744 - acc: 0.7579 - val_loss: 1.4162 - val_acc: 0.6890\n",
            "Epoch 142/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 0.8679 - acc: 0.7574 - val_loss: 1.3655 - val_acc: 0.6921\n",
            "Epoch 143/200\n",
            "8731/8731 [==============================] - 2s 195us/step - loss: 0.8706 - acc: 0.7529 - val_loss: 1.3951 - val_acc: 0.6797\n",
            "Epoch 144/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 0.8747 - acc: 0.7511 - val_loss: 1.5165 - val_acc: 0.6787\n",
            "Epoch 145/200\n",
            "8731/8731 [==============================] - 2s 190us/step - loss: 0.9185 - acc: 0.7483 - val_loss: 1.4662 - val_acc: 0.6766\n",
            "Epoch 146/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 0.8841 - acc: 0.7510 - val_loss: 1.4350 - val_acc: 0.6777\n",
            "Epoch 147/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.8712 - acc: 0.7542 - val_loss: 1.4240 - val_acc: 0.6787\n",
            "Epoch 148/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.8576 - acc: 0.7565 - val_loss: 1.4179 - val_acc: 0.6859\n",
            "Epoch 149/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.8487 - acc: 0.7603 - val_loss: 1.4015 - val_acc: 0.6818\n",
            "Epoch 150/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.8551 - acc: 0.7580 - val_loss: 1.4161 - val_acc: 0.6900\n",
            "Epoch 151/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.8669 - acc: 0.7595 - val_loss: 1.5454 - val_acc: 0.6663\n",
            "Epoch 152/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.8954 - acc: 0.7455 - val_loss: 1.5008 - val_acc: 0.6869\n",
            "Epoch 153/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 0.8381 - acc: 0.7587 - val_loss: 1.5580 - val_acc: 0.6735\n",
            "Epoch 154/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.8547 - acc: 0.7614 - val_loss: 1.4825 - val_acc: 0.6818\n",
            "Epoch 155/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.8498 - acc: 0.7586 - val_loss: 1.4346 - val_acc: 0.6910\n",
            "Epoch 156/200\n",
            "8731/8731 [==============================] - 2s 190us/step - loss: 0.8254 - acc: 0.7652 - val_loss: 1.4570 - val_acc: 0.6952\n",
            "Epoch 157/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 0.8546 - acc: 0.7580 - val_loss: 1.4639 - val_acc: 0.6838\n",
            "Epoch 158/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8393 - acc: 0.7626 - val_loss: 1.4654 - val_acc: 0.6807\n",
            "Epoch 159/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 0.8495 - acc: 0.7611 - val_loss: 1.4630 - val_acc: 0.6880\n",
            "Epoch 160/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8539 - acc: 0.7628 - val_loss: 1.4850 - val_acc: 0.6890\n",
            "Epoch 161/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8511 - acc: 0.7613 - val_loss: 1.4138 - val_acc: 0.6859\n",
            "Epoch 162/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.8555 - acc: 0.7617 - val_loss: 1.5004 - val_acc: 0.6818\n",
            "Epoch 163/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 0.8319 - acc: 0.7673 - val_loss: 1.4653 - val_acc: 0.6756\n",
            "Epoch 164/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.8413 - acc: 0.7605 - val_loss: 1.5322 - val_acc: 0.6797\n",
            "Epoch 165/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.8354 - acc: 0.7667 - val_loss: 1.4366 - val_acc: 0.6756\n",
            "Epoch 166/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.8156 - acc: 0.7720 - val_loss: 1.4826 - val_acc: 0.6890\n",
            "Epoch 167/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 0.8227 - acc: 0.7650 - val_loss: 1.3987 - val_acc: 0.6869\n",
            "Epoch 168/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8268 - acc: 0.7661 - val_loss: 1.5177 - val_acc: 0.6849\n",
            "Epoch 169/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.8176 - acc: 0.7647 - val_loss: 1.4893 - val_acc: 0.6859\n",
            "Epoch 170/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.8238 - acc: 0.7699 - val_loss: 1.4337 - val_acc: 0.6756\n",
            "Epoch 171/200\n",
            "8731/8731 [==============================] - 2s 190us/step - loss: 0.8265 - acc: 0.7674 - val_loss: 1.4123 - val_acc: 0.6869\n",
            "Epoch 172/200\n",
            "8731/8731 [==============================] - 2s 181us/step - loss: 0.8215 - acc: 0.7673 - val_loss: 1.4812 - val_acc: 0.6777\n",
            "Epoch 173/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.8414 - acc: 0.7652 - val_loss: 1.4787 - val_acc: 0.6756\n",
            "Epoch 174/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.8313 - acc: 0.7688 - val_loss: 1.4143 - val_acc: 0.6900\n",
            "Epoch 175/200\n",
            "8731/8731 [==============================] - 2s 183us/step - loss: 0.8083 - acc: 0.7715 - val_loss: 1.4907 - val_acc: 0.6982\n",
            "Epoch 176/200\n",
            "8731/8731 [==============================] - 2s 190us/step - loss: 0.8469 - acc: 0.7564 - val_loss: 1.4211 - val_acc: 0.6962\n",
            "Epoch 177/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.8052 - acc: 0.7692 - val_loss: 1.4508 - val_acc: 0.6910\n",
            "Epoch 178/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.7939 - acc: 0.7732 - val_loss: 1.4714 - val_acc: 0.6890\n",
            "Epoch 179/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.8161 - acc: 0.7705 - val_loss: 1.5390 - val_acc: 0.6807\n",
            "Epoch 180/200\n",
            "8731/8731 [==============================] - 2s 182us/step - loss: 0.8249 - acc: 0.7674 - val_loss: 1.3990 - val_acc: 0.6972\n",
            "Epoch 181/200\n",
            "8731/8731 [==============================] - 2s 187us/step - loss: 0.7958 - acc: 0.7686 - val_loss: 1.4209 - val_acc: 0.6900\n",
            "Epoch 182/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.7860 - acc: 0.7726 - val_loss: 1.4468 - val_acc: 0.6880\n",
            "Epoch 183/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.8080 - acc: 0.7685 - val_loss: 1.5381 - val_acc: 0.6838\n",
            "Epoch 184/200\n",
            "8731/8731 [==============================] - 2s 185us/step - loss: 0.8322 - acc: 0.7681 - val_loss: 1.5260 - val_acc: 0.6777\n",
            "Epoch 185/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.7974 - acc: 0.7702 - val_loss: 1.4318 - val_acc: 0.6962\n",
            "Epoch 186/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.7907 - acc: 0.7704 - val_loss: 1.4922 - val_acc: 0.6972\n",
            "Epoch 187/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 0.8048 - acc: 0.7708 - val_loss: 1.4597 - val_acc: 0.6972\n",
            "Epoch 188/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.7794 - acc: 0.7795 - val_loss: 1.5288 - val_acc: 0.6694\n",
            "Epoch 189/200\n",
            "8731/8731 [==============================] - 2s 184us/step - loss: 0.7956 - acc: 0.7728 - val_loss: 1.4516 - val_acc: 0.6880\n",
            "Epoch 190/200\n",
            "8731/8731 [==============================] - 2s 192us/step - loss: 0.7833 - acc: 0.7729 - val_loss: 1.4655 - val_acc: 0.6849\n",
            "Epoch 191/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.8127 - acc: 0.7738 - val_loss: 1.4879 - val_acc: 0.6807\n",
            "Epoch 192/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 0.8512 - acc: 0.7627 - val_loss: 1.4420 - val_acc: 0.7013\n",
            "Epoch 193/200\n",
            "8731/8731 [==============================] - 2s 194us/step - loss: 0.8017 - acc: 0.7709 - val_loss: 1.5758 - val_acc: 0.6859\n",
            "Epoch 194/200\n",
            "8731/8731 [==============================] - 2s 193us/step - loss: 0.7819 - acc: 0.7778 - val_loss: 1.4144 - val_acc: 0.6931\n",
            "Epoch 195/200\n",
            "8731/8731 [==============================] - 2s 197us/step - loss: 0.7718 - acc: 0.7815 - val_loss: 1.4262 - val_acc: 0.6818\n",
            "Epoch 196/200\n",
            "8731/8731 [==============================] - 2s 191us/step - loss: 0.7622 - acc: 0.7807 - val_loss: 1.5642 - val_acc: 0.6797\n",
            "Epoch 197/200\n",
            "8731/8731 [==============================] - 2s 188us/step - loss: 0.7597 - acc: 0.7792 - val_loss: 1.4362 - val_acc: 0.6880\n",
            "Epoch 198/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.7895 - acc: 0.7769 - val_loss: 1.4509 - val_acc: 0.6869\n",
            "Epoch 199/200\n",
            "8731/8731 [==============================] - 2s 186us/step - loss: 0.7795 - acc: 0.7778 - val_loss: 1.3663 - val_acc: 0.7044\n",
            "Epoch 200/200\n",
            "8731/8731 [==============================] - 2s 189us/step - loss: 0.8000 - acc: 0.7776 - val_loss: 1.4631 - val_acc: 0.6921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njpOFuLg7juNkIf8PcSeMGgMudJ4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVGUGETFXVEUJQZRcVcURYlB/j9TzwU/J5x8CgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsA8lY54BpYE",
        "colab_type": "text"
      },
      "source": [
        "### Testing the model with an unseen file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-5dedNjBo1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "prediction = model.predict(np.array(tk.texts_to_sequences(text)))\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAD6dQa3GfiP",
        "colab_type": "text"
      },
      "source": [
        "###Save Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knjT7nY8GfA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('urban_sound.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyRRiwEGGddg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ipcFNaULqsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "# This line must be executed before loading Keras model.\n",
        "K.set_learning_phase(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9-qXwyVLtLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c01f9ca5-0d22-4309-be78-ee211b6ae0d9"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('target_model/urban_sound.h5')\n",
        "print(model.outputs)\n",
        "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
        "print(model.inputs)\n",
        "# [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor 'dense_2_1/Softmax:0' shape=(?, 44) dtype=float32>]\n",
            "[<tf.Tensor 'conv2d_1_input_1:0' shape=(?, 10, 51, 1) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK3aAKpqMFvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
        "    \"\"\"\n",
        "    Freezes the state of a session into a pruned computation graph.\n",
        "\n",
        "    Creates a new computation graph where variable nodes are replaced by\n",
        "    constants taking their current value in the session. The new graph will be\n",
        "    pruned so subgraphs that are not necessary to compute the requested\n",
        "    outputs are removed.\n",
        "    @param session The TensorFlow session to be frozen.\n",
        "    @param keep_var_names A list of variable names that should not be frozen,\n",
        "                          or None to freeze all the variables in the graph.\n",
        "    @param output_names Names of the relevant graph outputs.\n",
        "    @param clear_devices Remove the device directives from the graph for better portability.\n",
        "    @return The frozen graph definition.\n",
        "    \"\"\"\n",
        "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
        "    graph = session.graph\n",
        "    with graph.as_default():\n",
        "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
        "        output_names = output_names or []\n",
        "        output_names += [v.op.name for v in tf.global_variables()]\n",
        "        # Graph -> GraphDef ProtoBuf\n",
        "        input_graph_def = graph.as_graph_def()\n",
        "        if clear_devices:\n",
        "            for node in input_graph_def.node:\n",
        "                node.device = \"\"\n",
        "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
        "                                                      output_names, freeze_var_names)\n",
        "        return frozen_graph\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4S5mtJjMwdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8febea0e-a399-47c3-9359-11f74dff4c17"
      },
      "source": [
        "import tensorflow as tf\n",
        "frozen_graph = freeze_session(K.get_session(),\n",
        "                              output_names=[out.op.name for out in model.outputs])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-66f248686223>:28: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.compat.v1.graph_util.extract_sub_graph\n",
            "INFO:tensorflow:Froze 438 variables.\n",
            "INFO:tensorflow:Converted 438 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyrvG3C2M2of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5a376f1-8db7-4f47-f8c2-4f279fef2f88"
      },
      "source": [
        "tf.train.write_graph(frozen_graph, \"model\", \"urban_sound_model.pb\", as_text=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model/tf_model.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQYm890ntf12",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Zl4IuyPrM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(history.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAufMuSHEWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXTfd8MKHoYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm5FlvfX88wo",
        "colab_type": "text"
      },
      "source": [
        "##Alternate folder train and test structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9njsm5MskSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = wav2mfcc('/content/small-urban-sound-dataset/tiny-dataset/crackling_fire/1-17150-A.wav')\n",
        "\n",
        "#X_train = X_train.reshape(X_train.shape[0], 10, 51, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARF4iPLZXH7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sample.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7phdcHrqXCat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_reshape = sample.reshape(sample(10,51,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5xmQdSWFBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(get_labels() [0] [np.argmax(model.predict(sample_reshape))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiLUN--y0u79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBULmNeFteL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "base_directory ='/content/target_dataset/'\n",
        "os.mkdir(base_directory)\n",
        "train_dir = os.path.join(base_directory, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_directory, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_directory, 'test')\n",
        "os.mkdir(test_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDMMKPgkXSko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dataset_dir = '/content/Sound-Datasets/combined_datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcURx0euURiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gunshot_dir = os.path.join(train_dir, 'gun_shot')\n",
        "os.mkdir(train_gunshot_dir)\n",
        "train_dogbark_dir = os.path.join(train_dir, 'dog_bark')\n",
        "os.mkdir(train_dogbark_dir)\n",
        "\n",
        "validation_gunshot_dir = os.path.join(validation_dir, 'gun_shot')\n",
        "os.mkdir(validation_gunshot_dir)\n",
        "validation_dogbark_dir = os.path.join(validation_dir, 'dog_bark')\n",
        "os.mkdir(validation_dogbark_dir)\n",
        "\n",
        "test_gunshot_dir = os.path.join(test_dir, 'gun_shot')\n",
        "os.mkdir(test_gunshot_dir)\n",
        "test_dogbark_dir = os.path.join(test_dir, 'dog_bark')\n",
        "os.mkdir(test_dogbark_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-fuVCQZWWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames_dog = os.listdir('/content/Sound-Datasets/combined_datasets/dog_bark')\n",
        "fnames_gun = os.listdir('/content/Sound-Datasets/combined_datasets/gun_shot')\n",
        "fnames = os.listdir('/content/Sound-Datasets/combined_datasets/dog_bark')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54t8veJLZdw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(fnames)\n",
        "size = len(fnames)\n",
        "train_percentage = 0.8\n",
        "validation_percentage = 0.1\n",
        "test_percentage = 0.1\n",
        "print('train percentage = %f' %train_percentage)\n",
        "train_size = int(round(size * (train_percentage)))\n",
        "validation_size = int(round(size * (validation_percentage)))\n",
        "test_size = int(round(size * (test_percentage)))\n",
        "print(size)\n",
        "print('train_size = %i' %train_size)\n",
        "print('validation_size = %i' %validation_size)\n",
        "print('test_size = %i' %test_size)\n",
        "total = train_size + validation_size + test_size\n",
        "print(total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pojp7QvbfKch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#os.chdir('/content/combined_datasets/dog_bark')\n",
        "train_list=[]\n",
        "validation_list=[]\n",
        "test_list=[]\n",
        "\n",
        "train_list = fnames[0:train_size]\n",
        "validation_list = fnames[train_size:train_size+validation_size]\n",
        "test_list = fnames[train_size+validation_size:total]\n",
        "\n",
        "\n",
        "for train in train_list:\n",
        "  src_train = os.path.join(original_dataset_dir+'dog_bark', train )\n",
        "  dst_train = os.path.join('/content/target_dataset/train/dog_bark', train)\n",
        "  shutil.copyfile(src_train, dst_train)\n",
        "\n",
        "for validation in validation_list:\n",
        "  src_validation = os.path.join(original_dataset_dir+'dog_bark', validation)\n",
        "  dst_validation = os.path.join('/content/target_dataset/validation/dog_bark', validation)\n",
        "  shutil.copyfile(src_validation, dst_validation)\n",
        "  \n",
        "for test in test_list:\n",
        "  src_test = os.path.join(original_dataset_dir+'dog_bark', test)\n",
        "  dst_test = os.path.join('/content/target_dataset/test/dog_bark', test)\n",
        "  shutil.copyfile(src_test, dst_test)\n",
        "  \n",
        "        \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOB0kg2_DGCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames_train = os.listdir('/content/target_dataset/train/dog_bark')\n",
        "print(len(fnames_train))\n",
        "fnames_val = os.listdir('/content/target_dataset/validation/dog_bark')\n",
        "print(len(fnames_val))\n",
        "fnames_test = os.listdir('/content/target_dataset/test/dog_bark')\n",
        "print(len(fnames_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z94KvPBWU6kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_gunshot_dir = os.path.join(validation_dir, 'gun_shot')\n",
        "os.mkdir(validation_gunshot_dir)\n",
        "validation_dogbark_dir = os.path.join(validation_dir, 'dog_bark')\n",
        "os.mkdir(validation_dogbark_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imuKEMG8U8Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gunshot_dir = os.path.join(test_dir, 'gun_shot')\n",
        "os.mkdir(test_gunshot_dir)\n",
        "test_dogbark_dir = os.path.join(test_dir, 'dog_bark')\n",
        "os.mkdir(test_dogbark_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywdXdFQFRUXu",
        "colab_type": "text"
      },
      "source": [
        "###Preparing for google speech dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdio_TpuAE5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url='http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
        "os.makedirs(dest_directory)\n",
        "filename = data_url.split('/')[-1]\n",
        "filepath = os.path.join(dest_directory, filename)\n",
        "\n",
        "print(filename)\n",
        "print(filepath)\n",
        " \n",
        "def _progress(count, block_size, total_size):\n",
        "    sys.stdout.write('\\r>> Downloading %s %.1f%%' % \\\n",
        "            (filename, float(count * block_size) / float(total_size) * 100.0)) \n",
        "    sys.stdout.flush()\n",
        "\n",
        "urban_dataset_dir = '/content/combined_datasets/' \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z1f7OCcESAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
        "statinfo = os.stat(filepath)\n",
        "tf.logging.info('Successfully downloaded %s (%d bytes)', filename, statinfo.st_size)\n",
        "tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}