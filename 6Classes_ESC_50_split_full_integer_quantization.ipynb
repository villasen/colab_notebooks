{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6Classes-ESC-50-split-full-integer-quantization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villasen/colab_notebooks/blob/master/6Classes_ESC_50_split_full_integer_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JODOH57hjOj7",
        "colab_type": "text"
      },
      "source": [
        "### Download prepared ESC-50-splitted 16KHz sampled with silence removed from all files\n",
        "The script will point to the preprocessed files located in /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il6azaZ9ja4B",
        "colab_type": "code",
        "outputId": "ac3f5e7b-17a2-4844-d473-dad4f4372d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!git clone https://github.com/villasen/small-urban-sound-dataset\n",
        "!rm -r sample_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'small-urban-sound-dataset'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 35228 (delta 5), reused 115 (delta 4), pack-reused 35111\n",
            "Receiving objects: 100% (35228/35228), 976.62 MiB | 33.40 MiB/s, done.\n",
            "Resolving deltas: 100% (12613/12613), done.\n",
            "Checking out files: 100% (43923/43923), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abthPhyXj5C4",
        "colab_type": "text"
      },
      "source": [
        "### Select number of mfccs to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUpf2WGMlf1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MFCC=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGfwFBIEkMSo",
        "colab_type": "text"
      },
      "source": [
        "### Pulling libraries and defining functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_4YbGclluH",
        "colab_type": "code",
        "outputId": "b8e6b0a0-87aa-4e29-abb7-d81636bf4729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow\n",
        "import scipy\n",
        "import os, shutil\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from six.moves import urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import os.path\n",
        "from os import path\n",
        "from tensorflow.python.ops import io_ops\n",
        "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from numpy  import array\n",
        "from tensorflow.contrib.quantize.python import fold_batch_norms\n",
        "from tensorflow.contrib.quantize.python import quantize\n",
        "from tensorflow.python.framework import ops\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########### FUNCTIONS\n",
        "\n",
        "def urban_wav2mfcc(file_path, max_pad_len):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320)\n",
        "      \n",
        "    pad_width = max_pad_len - mfcc.shape[1]\n",
        "    #print(max_pad_len)\n",
        "    #print(mfcc.shape[1])\n",
        "    #print(pad_width)\n",
        "    if pad_width < 0: \n",
        "      print(mfcc.shape[1])\n",
        "      print(pad_width)\n",
        "      print(\"error in \"+ file_path)\n",
        "    \n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    return mfcc \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "def load_wav_file(wav_file):\n",
        "  with tf.Session(graph=tf.Graph()) as sess:\n",
        "      wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
        "      wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
        "      wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\n",
        "      return sess.run(\n",
        "          wav_decoder,\n",
        "          feed_dict={wav_filename_placeholder: wav_file}).audio.flatten()\n",
        "\n",
        "\n",
        "def get_mfccs(file):\n",
        "  try:\n",
        "      wave, sr = librosa.load(wavfile , mono=True, sr=None)\n",
        "      mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320, norm='ortho')\n",
        "      mfcc_scaled = np.mean(mfcc.T, axis=0)\n",
        "      \n",
        "  except Exception as error:\n",
        "    print(\"Error found handling file: \", file)\n",
        "    return None\n",
        "  \n",
        "  return mfcc_scaled\n",
        "      \n",
        "def normalize_data(mfcc_file, mean, std_dev ):\n",
        "  norm_file = (mfcc_file - (mean)) / std_dev\n",
        "  return norm_file\n",
        "\n",
        "\n",
        "\n",
        "class AudioAugmentation:\n",
        "    def read_audio_file(self, file_path):\n",
        "        input_length = 16000\n",
        "        data = librosa.core.load(file_path)[0]\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else:\n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data\n",
        "\n",
        "    def write_audio_file(self, file, data, sample_rate=16000):\n",
        "        librosa.output.write_wav(file, data, sample_rate)\n",
        "\n",
        "    def add_noise(self, data):\n",
        "            noise = np.random.randn(len(data))\n",
        "            data_noise = data + 0.005 * noise\n",
        "            return data_noise\n",
        "    def shift(self, data):\n",
        "            return np.roll(data, 1600)\n",
        "    def stretch(self, data, rate=1):\n",
        "            input_length = 16000\n",
        "            data = librosa.effects.time_stretch(data, rate)\n",
        "            if len(data) > input_length:\n",
        "                data = data[:input_length]\n",
        "            else:\n",
        "                data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "            return data\n",
        "    def plot_time_series(self, data):\n",
        "            fig = plt.figure(figsize=(10, 10))\n",
        "            plt.title('Raw wave ')\n",
        "            plt.ylabel('Amplitude')\n",
        "            plt.plot(np.linspace(0, 1, len(data)), data)\n",
        "            plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bjxtO2xaAqJ",
        "colab_type": "text"
      },
      "source": [
        "Download nightly version of tensorflow. Only use in case Tensorflow gets updated to 2.0 by default. This is not needed as of now 10/26/2019. When downloading this version, runtime needs to be  reset. Do it twice. First time produces an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av2Lnb_OaBGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu\n",
        "# Installing tf version 1.15\n",
        "! pip uninstall -y tensorflow\n",
        "#! pip install -U tf-nightly\n",
        "!pip install tf-nightly==1.15.0.dev20190821\n",
        "!rm -rf /tmp/urban_sound_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujr_FkmxkWFb",
        "colab_type": "text"
      },
      "source": [
        "### Function to build model. More layers can be added by repeating middle block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GlmRTDLlwHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Original model\n",
        "def build_urban_model():\n",
        " return keras.Sequential([\n",
        "\n",
        "# CNN layer     \n",
        "    keras.layers.Conv2D(64, (4,MFCC), strides=(2,2), padding='same', activation='relu', input_shape=(MFCC,51,1), kernel_regularizer=keras.regularizers.l2(0.001)),     \n",
        "\n",
        "# Depthwise layers - middle block . +++++++++++++++++++++++++\n",
        "    keras.layers.Dropout(0.5), \n",
        "    keras.layers.SeparableConv2D(64, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None), \n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Conv2D(64, (1,1), strides=(1,1), padding='same', use_bias=False, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "\n",
        "#+++++++++++++++++++++++++++++++\n",
        "     \n",
        "# final layer includes a averagepool and a dense layer     \n",
        "    keras.layers.AveragePooling2D(pool_size=(5, 25), strides=(2,2), padding='valid', data_format=None),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Flatten(data_format=None),\n",
        "    keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001),  activation='relu'),\n",
        "\n",
        "     \n",
        "## final layer, here number 6 is the number of classes. If more classes added this number needs to be changed\n",
        "    keras.layers.Dense(6, activation='softmax')     \n",
        "      \n",
        "      \n",
        "\n",
        "\n",
        " \n",
        " \n",
        " ])  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHgLTr5lO6cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_urban_model():\n",
        " return keras.Sequential([\n",
        "      \n",
        "    keras.layers.Conv2D(128, (4,MFCC), strides=(2,2), padding='same', activation='relu', input_shape=(MFCC,51,1), kernel_regularizer=keras.regularizers.l2(0.001)),     \n",
        "\n",
        "# Depthwise layers\n",
        "    #keras.layers.Dropout(0.5), \n",
        "    keras.layers.SeparableConv2D(128, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Conv2D(128, (1,1), strides=(1,1), padding='same', use_bias=False, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "\n",
        "# Depthwise layers\n",
        "    #keras.layers.Dropout(0.5), \n",
        "    keras.layers.SeparableConv2D(128, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Conv2D(128, (1,1), strides=(1,1), padding='same', use_bias=False, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "\n",
        "# Depthwise layers\n",
        "    \n",
        "    keras.layers.SeparableConv2D(128, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (1,1), strides=(1,1), padding='same', use_bias=False, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    \n",
        "# Depthwise layers\n",
        "    \n",
        "    keras.layers.SeparableConv2D(128, (3,3), strides=(1,1), data_format='channels_last', padding='same', depth_multiplier=1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (1,1), strides=(1,1), padding='same', use_bias=False, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    keras.layers.AveragePooling2D(pool_size=(5, 25), strides=(2,2), padding='valid', data_format=None),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Flatten(data_format=None),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001),  activation='relu'),\n",
        "  \n",
        "      \n",
        "    keras.layers.Dense(6, activation='softmax')     \n",
        "      \n",
        "      \n",
        "  ]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U42N6SR5lSjU",
        "colab_type": "text"
      },
      "source": [
        "### Preparing test files\n",
        "This will create folders 1) test_single_file, 2) target_npy_files 3) target_txt_files\n",
        "\n",
        "1) test_single_file\n",
        "    This folder contains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Fw6Js0l_fW",
        "colab_type": "code",
        "outputId": "74b0440d-9f55-45ad-b94e-b7a3cf0beec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DATA_PATH= '/content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/'\n",
        "\n",
        "\n",
        "\n",
        "labels = os.listdir('small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/')\n",
        "print(labels)\n",
        "\n",
        "test_single_file = '/content/test_single_file/'\n",
        "if path.exists('/content/test_single_file/') :\n",
        "    print (\"folder test_single exits, removing\")\n",
        "    !rm -rf /content/test_single_file\n",
        "os.mkdir(test_single_file)\n",
        "\n",
        "target_npy_files = \"/content/target_npy_files/\"\n",
        "if path.exists(\"/content/target_npy_files/\") :\n",
        "    print (\"folder target_npy_files exits, removing\")\n",
        "    !rm -rf /content/target_npy_files\n",
        "os.mkdir(target_npy_files)\n",
        "\n",
        "\n",
        "target_txt_files = \"/content/target_txt_files/\"\n",
        "if path.exists(\"/content/target_txt_files/\") :\n",
        "    print (\"folder target_txt_files folder exits, removing\")\n",
        "    !rm -rf /content/target_txt_files\n",
        "os.mkdir(target_txt_files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dog\n",
        "if path.exists(\"/content/test_single_file/dog\") :\n",
        "     print (\"folder test_single_file/dog exits, removing\")\n",
        "     !rm -rf /content/test_single_file/dog\n",
        "os.mkdir('/content/test_single_file/dog')\n",
        "\n",
        "\n",
        "# clapping\n",
        "if path.exists(\"/content/test_single_file/clapping\") :\n",
        "     print (\"folder test_single_file/clapping exits, removing\")\n",
        "     !rm -rf /content/test_single_file/clapping\n",
        "os.mkdir('/content/test_single_file/clapping')\n",
        "\n",
        "# door knock\n",
        "if path.exists(\"/content/test_single_file/door_knock\") :\n",
        "    print (\"folder test_single_file/door_knock exits, removing\")\n",
        "    !rm -rf /content/test_single_file/door_knock\n",
        "os.mkdir('/content/test_single_file/door_knock')\n",
        "\n",
        "# clock alarm\n",
        "if path.exists(\"/content/test_single_file/clock_alarm\") :\n",
        "    print (\"folder test_single_file/clock_alarm exits, removing\")\n",
        "    !rm -rf /content/test_single_file/clock_alarm\n",
        "os.mkdir('/content/test_single_file/clock_alarm')\n",
        "\n",
        "# glass_breaking\n",
        "if path.exists(\"/content/test_single_file/glass_breaking\") :\n",
        "    print (\"folder test_single_file/glass_breaking exits, removing\")\n",
        "    !rm -rf /content/test_single_file/glass_breaking\n",
        "os.mkdir('/content/test_single_file/glass_breaking')\n",
        "\n",
        "# fireworks\n",
        "if path.exists(\"/content/test_single_file/fireworks\") :\n",
        "    print (\"folder test_single_file/fireworks exits, removing\")\n",
        "    !rm -rf /content/test_single_file/fireworks\n",
        "os.mkdir('/content/test_single_file/fireworks')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['can_opening', 'sneezing', 'footsteps', 'vacuum_cleaner', 'crackling_fire', 'dog', 'train', 'breathing', 'crow', 'snoring', 'water_drops', 'car_horn', 'frog', 'cow', 'thunderstorm', 'toilet_flush', 'chirping_birds', 'sheep', 'church_bells', 'fireworks', 'door_wood_creacks', '_background_noise_', 'washing_machine', 'crying_baby', 'airplane', 'handsaw', 'brushing_teeth', 'clock_alarm', 'mouse_click', 'door_knock', 'keyboard_typing', 'wind', 'crickets', 'laughing', 'pig', 'clapping', 'siren', 'cat', 'sea_waves', 'insects', 'glass_breaking', 'clock_tick', 'pouring_water', 'hen', 'coughing', 'rain', 'chainsaw', 'engine', 'drinking_sipping', 'rooster', 'Helicopter']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V1VYJ-mndqV",
        "colab_type": "text"
      },
      "source": [
        "Three individual files are displaced to folder /test_single_file to be prepared for testing the model. The files are moved instead of copied because we don't want the model to see these files beforehand and see how well it can generalize (detect new data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdsLbst4gp_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clapping/clapping-E-3-177082-A.wav  /content/test_single_file/clapping/\n",
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/dog/dog-A-5-208030-A.wav  /content/test_single_file/dog/\n",
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/door_knock/door_knock-B-1-101336-A.wav  /content/test_single_file/door_knock/\n",
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clock_alarm/clock_alarm-A-2-104476-A.wav  /content/test_single_file/clock_alarm/\n",
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/glass_breaking/glass_breaking-B-4-204777-B.wav /content/test_single_file/glass_breaking/\n",
        "!mv  /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/fireworks/fireworks-A-2-117615-D.wav  /content/test_single_file/fireworks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgo4u8mBipHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clapping/clapping-E-4-189828-A.wav /content/test_single_file/clapping/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/dog/dog-E-3-144028-A.wav  /content/test_single_file/dog/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/door_knock/door_knock-A-2-133889-A.wav  /content/test_single_file/door_knock/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clock_alarm/clock_alarm-B-3-117883-A.wav  /content/test_single_file/clock_alarm/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/glass_breaking/glass_breaking-A-1-88807-A.wav  /content/test_single_file/glass_breaking/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/fireworks/fireworks-A-4-119648-A.wav  /content/test_single_file/fireworks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwlAwHTPjlq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clapping/clapping-E-2-25292-A.wav /content/test_single_file/clapping/  \n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/dog/dog-D-5-208030-A.wav  /content/test_single_file/dog/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/door_knock/door_knock-A-5-250026-B.wav  /content/test_single_file/door_knock/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/clock_alarm/clock_alarm-B-3-132340-A.wav  /content/test_single_file/clock_alarm/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/glass_breaking/glass_breaking-A-4-212698-A.wav  /content/test_single_file/glass_breaking/\n",
        "!mv /content/small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/fireworks/fireworks-E-2-117617-A.wav  /content/test_single_file/fireworks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGrOOXC6oDUv",
        "colab_type": "text"
      },
      "source": [
        "### Files can be inspected with librosa to see their shape in time vs intensity and time vs frequency (Spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3JHLue21PXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, sr= librosa.load('test_single_file/clapping/clapping-E-3-177082-A.wav', sr=16000)\n",
        "print(x.shape)\n",
        "print(sr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "\n",
        "\n",
        "X = librosa.stft(x)\n",
        "Xdb = librosa.amplitude_to_db(abs(X))\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio('test_single_file/dog/dog-A-5-208030-A.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNcSAoMzE8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, sr= librosa.load('test_single_file/dog/dog-A-5-208030-A.wav', sr=16000)\n",
        "print(x.shape)\n",
        "print(sr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "\n",
        "\n",
        "X = librosa.stft(x)\n",
        "Xdb = librosa.amplitude_to_db(abs(X))\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio('test_single_file/dog/dog-A-5-208030-A.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCf3vgP108kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, sr= librosa.load('test_single_file/dog/dog-D-5-208030-A.wav', sr=16000)\n",
        "print(x.shape)\n",
        "print(sr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "\n",
        "\n",
        "X = librosa.stft(x)\n",
        "Xdb = librosa.amplitude_to_db(abs(X))\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio('test_single_file/dog/dog-D-5-208030-A.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrFeDKR93hGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, sr= librosa.load('test_single_file/dog/dog-E-3-144028-A.wav', sr=16000)\n",
        "print(x.shape)\n",
        "print(sr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "\n",
        "\n",
        "X = librosa.stft(x)\n",
        "Xdb = librosa.amplitude_to_db(abs(X))\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio('test_single_file/dog/dog-E-3-144028-A.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11MslIwJXJR",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsGcsO-EJWT5",
        "colab_type": "code",
        "outputId": "6778f9cc-e645-48bd-917f-11c40b3a1320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Data Augmentation \n",
        "#Create instance for augmentation\n",
        "aug = AudioAugmentation()\n",
        "\n",
        "path = DATA_PATH\n",
        "labels = os.listdir(path) \n",
        "print(labels)\n",
        "i=0\n",
        "for label in labels:\n",
        "  mfcc_vectors=[]\n",
        "   \n",
        "  wavefiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "  if label=='fireworks' or label=='clapping' or label=='door_knock' or label=='clock_alarm' \\\n",
        "             or label=='glass_breaking' or label=='dog': \n",
        "    #print(wavefiles)\n",
        "    for wavfile in wavefiles:\n",
        "        wave, sr = librosa.load(wavfile , mono=True, sr=None)\n",
        "        data_noise = aug.add_noise(wave)\n",
        "        data_shift = aug.shift(wave)\n",
        "        #data_files = np.pad(data_noise, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        #data_vectors.append(data_files)\n",
        "        num =str(i)\n",
        "        #np.save( wavfile + '_' + num, data_noise)\n",
        "        aug.write_audio_file( 'small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/' + label + '/' + 'augmented_noise_' + num + '.wav'  , data_noise)\n",
        "        aug.write_audio_file( 'small-urban-sound-dataset/ESC-50-split/ESC-50_split_data_set_one-second-16KHz/' + label + '/' + 'augmented_shift_' + num + '.wav'  , data_shift)\n",
        "        i=i+1\n",
        "\n",
        "    print(label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['can_opening', 'sneezing', 'footsteps', 'vacuum_cleaner', 'crackling_fire', 'dog', 'train', 'breathing', 'crow', 'snoring', 'water_drops', 'car_horn', 'frog', 'cow', 'thunderstorm', 'toilet_flush', 'chirping_birds', 'sheep', 'church_bells', 'fireworks', 'door_wood_creacks', '_background_noise_', 'washing_machine', 'crying_baby', 'airplane', 'handsaw', 'brushing_teeth', 'clock_alarm', 'mouse_click', 'door_knock', 'keyboard_typing', 'wind', 'crickets', 'laughing', 'pig', 'clapping', 'siren', 'cat', 'sea_waves', 'insects', 'glass_breaking', 'clock_tick', 'pouring_water', 'hen', 'coughing', 'rain', 'chainsaw', 'engine', 'drinking_sipping', 'rooster', 'Helicopter']\n",
            "dog\n",
            "fireworks\n",
            "clock_alarm\n",
            "door_knock\n",
            "clapping\n",
            "glass_breaking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgcSb5LtyYEa",
        "colab_type": "text"
      },
      "source": [
        "### Selecting labels to convert from wav files to numpy arrays.\n",
        "The converted wav files to numpy arrays are concatenated to single vector. \n",
        "These mfcc vectors will be ready for input to training template model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnnA0W_onR4t",
        "colab_type": "code",
        "outputId": "6eb665cf-d100-4cc7-f8f5-fdae0ee91124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "path = DATA_PATH\n",
        "labels = os.listdir(path) \n",
        "print(labels)\n",
        "\n",
        "max_feature = 0\n",
        "for label in labels:\n",
        "  mfcc_vectors=[]\n",
        "   \n",
        "  wavefiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "    \n",
        "  \n",
        "  if label=='fireworks' or label=='clapping' or label=='door_knock' or label=='clock_alarm' \\\n",
        "             or label=='glass_breaking' or label=='dog': \n",
        "#  if label=='clapping': \n",
        "    for wavfile in wavefiles:\n",
        "      #print(label)      \n",
        "      max_pad_len = 51\n",
        "      #mfcc = urban_wav2mfcc(wavfile, 51)\n",
        "\n",
        "      \n",
        "      wave, sr = librosa.load(wavfile , mono=True, sr=None)\n",
        "      mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320, norm='ortho')\n",
        "      #mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320)\n",
        "      #mfcc = get_mfccs(wavfile)\n",
        "      \n",
        "      \n",
        "      #print(mfcc)\n",
        "      \n",
        "      pad_width = max_pad_len - mfcc.shape[1]\n",
        "      \n",
        "     # print(max_pad_len)\n",
        "     # print(mfcc.shape[1])\n",
        "     # print(pad_width)\n",
        "      \n",
        "      if pad_width < 0: \n",
        "        print(mfcc.shape[1])\n",
        "        print(pad_width)\n",
        "        print(\"error in \"+ wavefiles)\n",
        "      mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "      mfcc_vectors.append(mfcc)\n",
        "\n",
        "\n",
        "    np.save('/content/target_npy_files/' + label + '.npy', mfcc_vectors)\n",
        "    np.savetxt('/content/target_txt_files/' + label + '.txt', mfcc_vectors[2], delimiter=', ')\n",
        "    print(label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['can_opening', 'sneezing', 'footsteps', 'vacuum_cleaner', 'crackling_fire', 'dog', 'train', 'breathing', 'crow', 'snoring', 'water_drops', 'car_horn', 'frog', 'cow', 'thunderstorm', 'toilet_flush', 'chirping_birds', 'sheep', 'church_bells', 'fireworks', 'door_wood_creacks', '_background_noise_', 'washing_machine', 'crying_baby', 'airplane', 'handsaw', 'brushing_teeth', 'clock_alarm', 'mouse_click', 'door_knock', 'keyboard_typing', 'wind', 'crickets', 'laughing', 'pig', 'clapping', 'siren', 'cat', 'sea_waves', 'insects', 'glass_breaking', 'clock_tick', 'pouring_water', 'hen', 'coughing', 'rain', 'chainsaw', 'engine', 'drinking_sipping', 'rooster', 'Helicopter']\n",
            "dog\n",
            "fireworks\n",
            "clock_alarm\n",
            "door_knock\n",
            "clapping\n",
            "glass_breaking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8vZpK2W9D3o",
        "colab_type": "text"
      },
      "source": [
        "### If we want to convert all labels to numpy arrays\n",
        "The if condition is removed to allow all labels to be converted to numpy arrays.\n",
        "DO NOT use this block if intending to train. This builds all 50 cases. The training function will expect to train 50 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQxrjQw9BQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = DATA_PATH\n",
        "labels = os.listdir(path) \n",
        "print(labels)\n",
        "\n",
        "max_feature = 0\n",
        "for label in labels:\n",
        "  mfcc_vectors=[]\n",
        "   \n",
        "  wavefiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "    \n",
        "  \n",
        "#  if label=='fireworks' or label=='clapping' or label=='door_knock' or label=='clock_alarm' \\\n",
        "#             or label=='glass_breaking' or label=='dog': \n",
        "#  if label=='clapping': \n",
        "  for wavfile in wavefiles:\n",
        "    #print(label)      \n",
        "    max_pad_len = 51\n",
        "    #mfcc = urban_wav2mfcc(wavfile, 51)\n",
        "\n",
        "\n",
        "    wave, sr = librosa.load(wavfile , mono=True, sr=None)\n",
        "    #mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320, norm='ortho')\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=MFCC, n_fft=640, hop_length=320)\n",
        "    #mfcc = get_mfccs(wavfile)\n",
        "\n",
        "\n",
        "    #print(mfcc)\n",
        "\n",
        "    pad_width = max_pad_len - mfcc.shape[1]\n",
        "\n",
        "   # print(max_pad_len)\n",
        "   # print(mfcc.shape[1])\n",
        "   # print(pad_width)\n",
        "\n",
        "    if pad_width < 0: \n",
        "      print(mfcc.shape[1])\n",
        "      print(pad_width)\n",
        "      print(\"error in \"+ wavefiles)\n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    mfcc_vectors.append(mfcc)\n",
        "\n",
        "\n",
        "  np.save('/content/target_npy_files/' + label + '.npy', mfcc_vectors)\n",
        "  np.savetxt('/content/target_txt_files/' + label + '.txt', mfcc_vectors[2], delimiter=', ')\n",
        "  print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQnXKPVo9fkI",
        "colab_type": "text"
      },
      "source": [
        "### The training and evaluation data is split. \n",
        "The split ratio determines the percentage of data to be trained. The remaining is for evaluation (testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mflLiC8qYfpb",
        "colab_type": "code",
        "outputId": "99e58beb-fa75-43a1-f193-6710696ed3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "\n",
        "split_ratio = 0.9\n",
        "random_state = 42\n",
        "\n",
        "npy_files= os.listdir('/content/target_npy_files/')\n",
        "print(npy_files)\n",
        "\n",
        "X = np.load('/content/target_npy_files/' + npy_files[0])\n",
        "y = np.zeros(X.shape[0])\n",
        "#print(npy_files[0])\n",
        "#print(npy_files[1])\n",
        "#print(npy_files[2])\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "# # Append all of the dataset into one single array, same goes for \n",
        "for i, label in enumerate(npy_files[1:]):\n",
        "   x = np.load('/content/target_npy_files/' + label)\n",
        "  \n",
        "#     #x = np.load('/content/speech-numpy/' + label)\n",
        "\n",
        "   X = np.vstack((X, x))\n",
        "   y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "   \n",
        "\n",
        "#X_new = (X - (np.mean(X))) / (np.std(X))\n",
        "#X_std = (X -  / (X.max(axis=0)) - X.min(axis=0)\n",
        "#print(X.min(axis=0))\n",
        "#X_new = minmax_scale(X)\n",
        "# return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True) \n",
        "#X_min = min(X)\n",
        "#X_new = ( X - min(X)) / (max(X) - min(X))\n",
        "#X_std = np.std(X)\n",
        "#X_mean = np.mean(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], MFCC, 51, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], MFCC, 51, 1)\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['clock_alarm.npy', 'fireworks.npy', 'dog.npy', 'glass_breaking.npy', 'door_knock.npy', 'clapping.npy']\n",
            "(351, 20, 51)\n",
            "(351,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWd4Xt5h-Iz9",
        "colab_type": "text"
      },
      "source": [
        "### Training model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lg24Mc8aKf6",
        "colab_type": "code",
        "outputId": "d14a5999-5256-4cd2-f248-5ae69c66da7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!rm checkpoint\n",
        "!rm checkpoints.data-00000-of-00001\n",
        "!rm checkpoints.index\n",
        "!rm checkpoints.meta\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "\n",
        "classes=[\"door knock\", \"fireworks\", \"clapping\", \"dog\", \"glass breaking\", \"clock alarm\"]\n",
        "\n",
        "\n",
        "speech_graph = tf.Graph()\n",
        "speech_sess = tf.Session(graph=speech_graph)\n",
        "\n",
        "keras.backend.set_session(speech_sess)\n",
        "with speech_graph.as_default():\n",
        "     \n",
        "  #build my model\n",
        "  model = build_urban_model()\n",
        "  #give me model structure\n",
        "  model.summary()\n",
        "\n",
        "  #my own optimizer\n",
        "  Amartin = optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "  \n",
        "  model.compile(optimizer= 'adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  #model.compile(optimizer= Amartin, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  # run it\n",
        "  history = model.fit(X_train, y_train_hot, batch_size=100, epochs=200, verbose=1, validation_data=(X_test, y_test_hot))\n",
        "  #save my graph\n",
        "  \n",
        "  #real_label_batch = tf.argmax(y_test_hot, axis=1)\n",
        "  #y_pred=model.predict_classes(X_test)\n",
        "  #con_mat = tf.math.confusion_matrix(labels=real_label_batch, predictions=y_pred).numpy()   \n",
        "\n",
        "  #con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "  #con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "  #                     index = classes, \n",
        "  #                     columns = classes)\n",
        "\n",
        "  #figure = plt.figure(figsize=(6, 6))\n",
        " #sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "  #plt.tight_layout()\n",
        "  #plt.ylabel('True label')\n",
        "  #plt.xlabel('Predicted label')\n",
        "  #plt.show()  \n",
        "    \n",
        "  \n",
        "  saver = tf.train.Saver()\n",
        "  saver.save(speech_sess, 'checkpoints')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 10, 26, 128)       10368     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 10, 26, 128)       17664     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 26, 128)       16384     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 10, 26, 128)       17664     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 26, 128)       16384     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 10, 26, 128)       17664     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 26, 128)       16384     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 10, 26, 128)       17664     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 26, 128)       16384     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 3, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                24640     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 171,590\n",
            "Trainable params: 171,590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1541 samples, validate on 172 samples\n",
            "Epoch 1/200\n",
            "1541/1541 [==============================] - 1s 737us/step - loss: 2.2545 - acc: 0.2544 - val_loss: 2.0914 - val_acc: 0.2965\n",
            "Epoch 2/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 1.9910 - acc: 0.2849 - val_loss: 1.8252 - val_acc: 0.2965\n",
            "Epoch 3/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 1.7928 - acc: 0.2881 - val_loss: 1.6667 - val_acc: 0.2965\n",
            "Epoch 4/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 1.6647 - acc: 0.2842 - val_loss: 1.5772 - val_acc: 0.2965\n",
            "Epoch 5/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 1.5653 - acc: 0.3141 - val_loss: 1.4792 - val_acc: 0.3663\n",
            "Epoch 6/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 1.4805 - acc: 0.4173 - val_loss: 1.4518 - val_acc: 0.5058\n",
            "Epoch 7/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 1.4231 - acc: 0.4659 - val_loss: 1.3440 - val_acc: 0.5233\n",
            "Epoch 8/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 1.3249 - acc: 0.5049 - val_loss: 1.2418 - val_acc: 0.5233\n",
            "Epoch 9/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 1.2646 - acc: 0.5107 - val_loss: 1.2210 - val_acc: 0.5233\n",
            "Epoch 10/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 1.1970 - acc: 0.5367 - val_loss: 1.1450 - val_acc: 0.5872\n",
            "Epoch 11/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 1.1488 - acc: 0.5691 - val_loss: 1.0769 - val_acc: 0.6047\n",
            "Epoch 12/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 1.1185 - acc: 0.5775 - val_loss: 1.0688 - val_acc: 0.5988\n",
            "Epoch 13/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 1.0889 - acc: 0.5847 - val_loss: 0.9814 - val_acc: 0.6337\n",
            "Epoch 14/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.9917 - acc: 0.6119 - val_loss: 0.8832 - val_acc: 0.6802\n",
            "Epoch 15/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.9066 - acc: 0.6593 - val_loss: 0.7782 - val_acc: 0.7558\n",
            "Epoch 16/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.8326 - acc: 0.7054 - val_loss: 0.6959 - val_acc: 0.7733\n",
            "Epoch 17/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.7308 - acc: 0.7521 - val_loss: 0.6281 - val_acc: 0.7849\n",
            "Epoch 18/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.6908 - acc: 0.7541 - val_loss: 0.7268 - val_acc: 0.7500\n",
            "Epoch 19/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.6509 - acc: 0.7826 - val_loss: 0.6005 - val_acc: 0.7849\n",
            "Epoch 20/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.6266 - acc: 0.7820 - val_loss: 0.5256 - val_acc: 0.8430\n",
            "Epoch 21/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.5608 - acc: 0.7988 - val_loss: 0.5309 - val_acc: 0.8372\n",
            "Epoch 22/200\n",
            "1541/1541 [==============================] - 0s 186us/step - loss: 0.5535 - acc: 0.8060 - val_loss: 0.4750 - val_acc: 0.8779\n",
            "Epoch 23/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.5272 - acc: 0.8170 - val_loss: 0.4805 - val_acc: 0.8605\n",
            "Epoch 24/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.4973 - acc: 0.8469 - val_loss: 0.4257 - val_acc: 0.8953\n",
            "Epoch 25/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.4926 - acc: 0.8469 - val_loss: 0.4503 - val_acc: 0.8663\n",
            "Epoch 26/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.4772 - acc: 0.8592 - val_loss: 0.4077 - val_acc: 0.9012\n",
            "Epoch 27/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.4536 - acc: 0.8735 - val_loss: 0.4183 - val_acc: 0.8721\n",
            "Epoch 28/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.4176 - acc: 0.8890 - val_loss: 0.3953 - val_acc: 0.8953\n",
            "Epoch 29/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.4246 - acc: 0.8819 - val_loss: 0.3916 - val_acc: 0.9012\n",
            "Epoch 30/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.4198 - acc: 0.8761 - val_loss: 0.3677 - val_acc: 0.9012\n",
            "Epoch 31/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.3813 - acc: 0.8884 - val_loss: 0.3716 - val_acc: 0.8895\n",
            "Epoch 32/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.3820 - acc: 0.8929 - val_loss: 0.3498 - val_acc: 0.9070\n",
            "Epoch 33/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.3863 - acc: 0.8988 - val_loss: 0.3490 - val_acc: 0.9070\n",
            "Epoch 34/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.3724 - acc: 0.9072 - val_loss: 0.4405 - val_acc: 0.8779\n",
            "Epoch 35/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.4101 - acc: 0.8916 - val_loss: 0.3546 - val_acc: 0.9012\n",
            "Epoch 36/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.3857 - acc: 0.8936 - val_loss: 0.3336 - val_acc: 0.9244\n",
            "Epoch 37/200\n",
            "1541/1541 [==============================] - 0s 201us/step - loss: 0.3377 - acc: 0.9124 - val_loss: 0.3502 - val_acc: 0.9070\n",
            "Epoch 38/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.3281 - acc: 0.9176 - val_loss: 0.3324 - val_acc: 0.9070\n",
            "Epoch 39/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.3299 - acc: 0.9085 - val_loss: 0.2969 - val_acc: 0.9360\n",
            "Epoch 40/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.2956 - acc: 0.9338 - val_loss: 0.3060 - val_acc: 0.9360\n",
            "Epoch 41/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.2889 - acc: 0.9221 - val_loss: 0.2868 - val_acc: 0.9302\n",
            "Epoch 42/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.2987 - acc: 0.9228 - val_loss: 0.2948 - val_acc: 0.9012\n",
            "Epoch 43/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.3288 - acc: 0.9208 - val_loss: 0.2944 - val_acc: 0.9244\n",
            "Epoch 44/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.3197 - acc: 0.9137 - val_loss: 0.2569 - val_acc: 0.9360\n",
            "Epoch 45/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.2753 - acc: 0.9286 - val_loss: 0.2771 - val_acc: 0.9244\n",
            "Epoch 46/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.2685 - acc: 0.9319 - val_loss: 0.3136 - val_acc: 0.9070\n",
            "Epoch 47/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.3023 - acc: 0.9228 - val_loss: 0.2622 - val_acc: 0.9477\n",
            "Epoch 48/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.2773 - acc: 0.9351 - val_loss: 0.2546 - val_acc: 0.9186\n",
            "Epoch 49/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.2497 - acc: 0.9429 - val_loss: 0.2687 - val_acc: 0.9128\n",
            "Epoch 50/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.3021 - acc: 0.9273 - val_loss: 0.2532 - val_acc: 0.9477\n",
            "Epoch 51/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.2494 - acc: 0.9455 - val_loss: 0.2316 - val_acc: 0.9360\n",
            "Epoch 52/200\n",
            "1541/1541 [==============================] - 0s 200us/step - loss: 0.2267 - acc: 0.9546 - val_loss: 0.2330 - val_acc: 0.9477\n",
            "Epoch 53/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.2258 - acc: 0.9500 - val_loss: 0.2380 - val_acc: 0.9477\n",
            "Epoch 54/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.2281 - acc: 0.9409 - val_loss: 0.2294 - val_acc: 0.9477\n",
            "Epoch 55/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.2182 - acc: 0.9513 - val_loss: 0.2269 - val_acc: 0.9477\n",
            "Epoch 56/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.1998 - acc: 0.9565 - val_loss: 0.1991 - val_acc: 0.9477\n",
            "Epoch 57/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.2089 - acc: 0.9500 - val_loss: 0.2109 - val_acc: 0.9477\n",
            "Epoch 58/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.2010 - acc: 0.9611 - val_loss: 0.1873 - val_acc: 0.9651\n",
            "Epoch 59/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.2456 - acc: 0.9364 - val_loss: 0.4665 - val_acc: 0.9070\n",
            "Epoch 60/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.2490 - acc: 0.9390 - val_loss: 0.2670 - val_acc: 0.9419\n",
            "Epoch 61/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.2232 - acc: 0.9552 - val_loss: 0.2035 - val_acc: 0.9360\n",
            "Epoch 62/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1903 - acc: 0.9624 - val_loss: 0.1982 - val_acc: 0.9535\n",
            "Epoch 63/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.1702 - acc: 0.9676 - val_loss: 0.1929 - val_acc: 0.9593\n",
            "Epoch 64/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1687 - acc: 0.9656 - val_loss: 0.1860 - val_acc: 0.9651\n",
            "Epoch 65/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1618 - acc: 0.9689 - val_loss: 0.1811 - val_acc: 0.9477\n",
            "Epoch 66/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.1721 - acc: 0.9637 - val_loss: 0.1893 - val_acc: 0.9477\n",
            "Epoch 67/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1594 - acc: 0.9708 - val_loss: 0.1917 - val_acc: 0.9477\n",
            "Epoch 68/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1699 - acc: 0.9695 - val_loss: 0.2309 - val_acc: 0.9477\n",
            "Epoch 69/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1638 - acc: 0.9727 - val_loss: 0.2162 - val_acc: 0.9593\n",
            "Epoch 70/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.1711 - acc: 0.9669 - val_loss: 0.1511 - val_acc: 0.9767\n",
            "Epoch 71/200\n",
            "1541/1541 [==============================] - 0s 200us/step - loss: 0.1643 - acc: 0.9714 - val_loss: 0.2019 - val_acc: 0.9535\n",
            "Epoch 72/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.1861 - acc: 0.9637 - val_loss: 0.2121 - val_acc: 0.9477\n",
            "Epoch 73/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.1648 - acc: 0.9714 - val_loss: 0.1684 - val_acc: 0.9593\n",
            "Epoch 74/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.1552 - acc: 0.9747 - val_loss: 0.2289 - val_acc: 0.9477\n",
            "Epoch 75/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1702 - acc: 0.9701 - val_loss: 0.1815 - val_acc: 0.9651\n",
            "Epoch 76/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.1587 - acc: 0.9676 - val_loss: 0.1609 - val_acc: 0.9767\n",
            "Epoch 77/200\n",
            "1541/1541 [==============================] - 0s 200us/step - loss: 0.1417 - acc: 0.9766 - val_loss: 0.1520 - val_acc: 0.9767\n",
            "Epoch 78/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.1414 - acc: 0.9760 - val_loss: 0.1718 - val_acc: 0.9651\n",
            "Epoch 79/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.1678 - acc: 0.9656 - val_loss: 0.1967 - val_acc: 0.9535\n",
            "Epoch 80/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.2176 - acc: 0.9546 - val_loss: 0.3153 - val_acc: 0.9651\n",
            "Epoch 81/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1953 - acc: 0.9585 - val_loss: 0.1648 - val_acc: 0.9593\n",
            "Epoch 82/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.1479 - acc: 0.9760 - val_loss: 0.1986 - val_acc: 0.9593\n",
            "Epoch 83/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.1509 - acc: 0.9734 - val_loss: 0.1626 - val_acc: 0.9651\n",
            "Epoch 84/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1342 - acc: 0.9799 - val_loss: 0.1795 - val_acc: 0.9593\n",
            "Epoch 85/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.1229 - acc: 0.9799 - val_loss: 0.1892 - val_acc: 0.9593\n",
            "Epoch 86/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1234 - acc: 0.9844 - val_loss: 0.1176 - val_acc: 0.9826\n",
            "Epoch 87/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1256 - acc: 0.9831 - val_loss: 0.1712 - val_acc: 0.9593\n",
            "Epoch 88/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1182 - acc: 0.9851 - val_loss: 0.1338 - val_acc: 0.9767\n",
            "Epoch 89/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1174 - acc: 0.9831 - val_loss: 0.1148 - val_acc: 0.9826\n",
            "Epoch 90/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.1190 - acc: 0.9838 - val_loss: 0.1373 - val_acc: 0.9709\n",
            "Epoch 91/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1270 - acc: 0.9779 - val_loss: 0.2526 - val_acc: 0.9419\n",
            "Epoch 92/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1594 - acc: 0.9650 - val_loss: 0.2108 - val_acc: 0.9535\n",
            "Epoch 93/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.1420 - acc: 0.9779 - val_loss: 0.1649 - val_acc: 0.9651\n",
            "Epoch 94/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.1155 - acc: 0.9812 - val_loss: 0.1413 - val_acc: 0.9767\n",
            "Epoch 95/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1055 - acc: 0.9831 - val_loss: 0.1217 - val_acc: 0.9767\n",
            "Epoch 96/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1107 - acc: 0.9864 - val_loss: 0.1355 - val_acc: 0.9651\n",
            "Epoch 97/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.1094 - acc: 0.9851 - val_loss: 0.1370 - val_acc: 0.9767\n",
            "Epoch 98/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 0.1068 - acc: 0.9857 - val_loss: 0.1592 - val_acc: 0.9593\n",
            "Epoch 99/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.1387 - acc: 0.9773 - val_loss: 0.1447 - val_acc: 0.9651\n",
            "Epoch 100/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.1085 - acc: 0.9877 - val_loss: 0.1206 - val_acc: 0.9826\n",
            "Epoch 101/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1198 - acc: 0.9838 - val_loss: 0.1322 - val_acc: 0.9709\n",
            "Epoch 102/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1181 - acc: 0.9844 - val_loss: 0.1436 - val_acc: 0.9709\n",
            "Epoch 103/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1057 - acc: 0.9883 - val_loss: 0.1353 - val_acc: 0.9767\n",
            "Epoch 104/200\n",
            "1541/1541 [==============================] - 0s 203us/step - loss: 0.0997 - acc: 0.9896 - val_loss: 0.1046 - val_acc: 0.9826\n",
            "Epoch 105/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0968 - acc: 0.9903 - val_loss: 0.1213 - val_acc: 0.9767\n",
            "Epoch 106/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0971 - acc: 0.9890 - val_loss: 0.1399 - val_acc: 0.9651\n",
            "Epoch 107/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0989 - acc: 0.9903 - val_loss: 0.1198 - val_acc: 0.9767\n",
            "Epoch 108/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0924 - acc: 0.9916 - val_loss: 0.1160 - val_acc: 0.9826\n",
            "Epoch 109/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.1061 - acc: 0.9844 - val_loss: 0.1195 - val_acc: 0.9767\n",
            "Epoch 110/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.1186 - acc: 0.9838 - val_loss: 0.1306 - val_acc: 0.9709\n",
            "Epoch 111/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1044 - acc: 0.9870 - val_loss: 0.1641 - val_acc: 0.9593\n",
            "Epoch 112/200\n",
            "1541/1541 [==============================] - 0s 201us/step - loss: 0.1499 - acc: 0.9721 - val_loss: 0.1543 - val_acc: 0.9709\n",
            "Epoch 113/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1315 - acc: 0.9792 - val_loss: 0.1554 - val_acc: 0.9767\n",
            "Epoch 114/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1092 - acc: 0.9857 - val_loss: 0.1272 - val_acc: 0.9826\n",
            "Epoch 115/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1033 - acc: 0.9870 - val_loss: 0.1878 - val_acc: 0.9593\n",
            "Epoch 116/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1165 - acc: 0.9844 - val_loss: 0.1246 - val_acc: 0.9826\n",
            "Epoch 117/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.1025 - acc: 0.9877 - val_loss: 0.1285 - val_acc: 0.9767\n",
            "Epoch 118/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.1071 - acc: 0.9851 - val_loss: 0.1531 - val_acc: 0.9767\n",
            "Epoch 119/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.1159 - acc: 0.9825 - val_loss: 0.2019 - val_acc: 0.9593\n",
            "Epoch 120/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0926 - acc: 0.9890 - val_loss: 0.1296 - val_acc: 0.9709\n",
            "Epoch 121/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 0.1114 - acc: 0.9844 - val_loss: 0.1177 - val_acc: 0.9826\n",
            "Epoch 122/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.1017 - acc: 0.9896 - val_loss: 0.1284 - val_acc: 0.9826\n",
            "Epoch 123/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.1376 - acc: 0.9760 - val_loss: 0.1627 - val_acc: 0.9709\n",
            "Epoch 124/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.1036 - acc: 0.9870 - val_loss: 0.1558 - val_acc: 0.9767\n",
            "Epoch 125/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0937 - acc: 0.9916 - val_loss: 0.1322 - val_acc: 0.9826\n",
            "Epoch 126/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0966 - acc: 0.9883 - val_loss: 0.1694 - val_acc: 0.9709\n",
            "Epoch 127/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0882 - acc: 0.9922 - val_loss: 0.1247 - val_acc: 0.9767\n",
            "Epoch 128/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0879 - acc: 0.9909 - val_loss: 0.1152 - val_acc: 0.9826\n",
            "Epoch 129/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0802 - acc: 0.9955 - val_loss: 0.1261 - val_acc: 0.9767\n",
            "Epoch 130/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0850 - acc: 0.9929 - val_loss: 0.1114 - val_acc: 0.9884\n",
            "Epoch 131/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0913 - acc: 0.9896 - val_loss: 0.1397 - val_acc: 0.9767\n",
            "Epoch 132/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.1000 - acc: 0.9864 - val_loss: 0.1173 - val_acc: 0.9767\n",
            "Epoch 133/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0908 - acc: 0.9896 - val_loss: 0.1447 - val_acc: 0.9767\n",
            "Epoch 134/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0878 - acc: 0.9916 - val_loss: 0.0992 - val_acc: 0.9884\n",
            "Epoch 135/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0970 - acc: 0.9903 - val_loss: 0.1110 - val_acc: 0.9826\n",
            "Epoch 136/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 0.0905 - acc: 0.9922 - val_loss: 0.1193 - val_acc: 0.9767\n",
            "Epoch 137/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0875 - acc: 0.9896 - val_loss: 0.1602 - val_acc: 0.9709\n",
            "Epoch 138/200\n",
            "1541/1541 [==============================] - 0s 189us/step - loss: 0.1049 - acc: 0.9864 - val_loss: 0.1145 - val_acc: 0.9884\n",
            "Epoch 139/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.0870 - acc: 0.9929 - val_loss: 0.1543 - val_acc: 0.9826\n",
            "Epoch 140/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.0856 - acc: 0.9942 - val_loss: 0.1353 - val_acc: 0.9826\n",
            "Epoch 141/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0804 - acc: 0.9935 - val_loss: 0.1161 - val_acc: 0.9767\n",
            "Epoch 142/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0826 - acc: 0.9935 - val_loss: 0.0970 - val_acc: 0.9884\n",
            "Epoch 143/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0738 - acc: 0.9955 - val_loss: 0.0879 - val_acc: 0.9884\n",
            "Epoch 144/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0838 - acc: 0.9916 - val_loss: 0.0984 - val_acc: 0.9884\n",
            "Epoch 145/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0929 - acc: 0.9877 - val_loss: 0.1381 - val_acc: 0.9826\n",
            "Epoch 146/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.1451 - acc: 0.9734 - val_loss: 0.1501 - val_acc: 0.9709\n",
            "Epoch 147/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0995 - acc: 0.9864 - val_loss: 0.1810 - val_acc: 0.9651\n",
            "Epoch 148/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0884 - acc: 0.9896 - val_loss: 0.1324 - val_acc: 0.9709\n",
            "Epoch 149/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.0904 - acc: 0.9909 - val_loss: 0.1285 - val_acc: 0.9767\n",
            "Epoch 150/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0797 - acc: 0.9948 - val_loss: 0.1173 - val_acc: 0.9826\n",
            "Epoch 151/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0833 - acc: 0.9922 - val_loss: 0.1675 - val_acc: 0.9709\n",
            "Epoch 152/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0869 - acc: 0.9929 - val_loss: 0.1278 - val_acc: 0.9767\n",
            "Epoch 153/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.0800 - acc: 0.9935 - val_loss: 0.1518 - val_acc: 0.9709\n",
            "Epoch 154/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.0782 - acc: 0.9942 - val_loss: 0.1107 - val_acc: 0.9884\n",
            "Epoch 155/200\n",
            "1541/1541 [==============================] - 0s 201us/step - loss: 0.0757 - acc: 0.9961 - val_loss: 0.0881 - val_acc: 0.9884\n",
            "Epoch 156/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0703 - acc: 0.9974 - val_loss: 0.0882 - val_acc: 0.9884\n",
            "Epoch 157/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.0742 - acc: 0.9974 - val_loss: 0.0907 - val_acc: 0.9884\n",
            "Epoch 158/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0751 - acc: 0.9935 - val_loss: 0.1205 - val_acc: 0.9651\n",
            "Epoch 159/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0807 - acc: 0.9909 - val_loss: 0.1729 - val_acc: 0.9767\n",
            "Epoch 160/200\n",
            "1541/1541 [==============================] - 0s 198us/step - loss: 0.0785 - acc: 0.9929 - val_loss: 0.1154 - val_acc: 0.9767\n",
            "Epoch 161/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0947 - acc: 0.9870 - val_loss: 0.1105 - val_acc: 0.9709\n",
            "Epoch 162/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0760 - acc: 0.9948 - val_loss: 0.1130 - val_acc: 0.9767\n",
            "Epoch 163/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.0795 - acc: 0.9942 - val_loss: 0.1061 - val_acc: 0.9826\n",
            "Epoch 164/200\n",
            "1541/1541 [==============================] - 0s 201us/step - loss: 0.0773 - acc: 0.9935 - val_loss: 0.0865 - val_acc: 0.9884\n",
            "Epoch 165/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0801 - acc: 0.9916 - val_loss: 0.0992 - val_acc: 0.9884\n",
            "Epoch 166/200\n",
            "1541/1541 [==============================] - 0s 200us/step - loss: 0.0787 - acc: 0.9929 - val_loss: 0.1371 - val_acc: 0.9826\n",
            "Epoch 167/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 0.0741 - acc: 0.9942 - val_loss: 0.1863 - val_acc: 0.9651\n",
            "Epoch 168/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0756 - acc: 0.9942 - val_loss: 0.0803 - val_acc: 0.9884\n",
            "Epoch 169/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0690 - acc: 0.9974 - val_loss: 0.0979 - val_acc: 0.9826\n",
            "Epoch 170/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0729 - acc: 0.9955 - val_loss: 0.0839 - val_acc: 0.9826\n",
            "Epoch 171/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0682 - acc: 0.9974 - val_loss: 0.0876 - val_acc: 0.9884\n",
            "Epoch 172/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0747 - acc: 0.9935 - val_loss: 0.1009 - val_acc: 0.9826\n",
            "Epoch 173/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0733 - acc: 0.9948 - val_loss: 0.0982 - val_acc: 0.9767\n",
            "Epoch 174/200\n",
            "1541/1541 [==============================] - 0s 199us/step - loss: 0.0697 - acc: 0.9968 - val_loss: 0.0891 - val_acc: 0.9826\n",
            "Epoch 175/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.0744 - acc: 0.9948 - val_loss: 0.1186 - val_acc: 0.9826\n",
            "Epoch 176/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0780 - acc: 0.9942 - val_loss: 0.1257 - val_acc: 0.9709\n",
            "Epoch 177/200\n",
            "1541/1541 [==============================] - 0s 205us/step - loss: 0.0707 - acc: 0.9955 - val_loss: 0.1261 - val_acc: 0.9826\n",
            "Epoch 178/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0715 - acc: 0.9929 - val_loss: 0.0835 - val_acc: 0.9942\n",
            "Epoch 179/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0679 - acc: 0.9955 - val_loss: 0.0978 - val_acc: 0.9942\n",
            "Epoch 180/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0722 - acc: 0.9948 - val_loss: 0.1195 - val_acc: 0.9826\n",
            "Epoch 181/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0752 - acc: 0.9929 - val_loss: 0.1424 - val_acc: 0.9651\n",
            "Epoch 182/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0853 - acc: 0.9909 - val_loss: 0.1030 - val_acc: 0.9709\n",
            "Epoch 183/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0762 - acc: 0.9935 - val_loss: 0.1338 - val_acc: 0.9767\n",
            "Epoch 184/200\n",
            "1541/1541 [==============================] - 0s 191us/step - loss: 0.0879 - acc: 0.9929 - val_loss: 0.1248 - val_acc: 0.9826\n",
            "Epoch 185/200\n",
            "1541/1541 [==============================] - 0s 200us/step - loss: 0.0861 - acc: 0.9929 - val_loss: 0.1918 - val_acc: 0.9593\n",
            "Epoch 186/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0865 - acc: 0.9903 - val_loss: 0.1317 - val_acc: 0.9709\n",
            "Epoch 187/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.0729 - acc: 0.9948 - val_loss: 0.1274 - val_acc: 0.9709\n",
            "Epoch 188/200\n",
            "1541/1541 [==============================] - 0s 193us/step - loss: 0.0712 - acc: 0.9955 - val_loss: 0.0921 - val_acc: 0.9826\n",
            "Epoch 189/200\n",
            "1541/1541 [==============================] - 0s 203us/step - loss: 0.0686 - acc: 0.9961 - val_loss: 0.0893 - val_acc: 0.9884\n",
            "Epoch 190/200\n",
            "1541/1541 [==============================] - 0s 196us/step - loss: 0.0637 - acc: 0.9981 - val_loss: 0.1034 - val_acc: 0.9884\n",
            "Epoch 191/200\n",
            "1541/1541 [==============================] - 0s 195us/step - loss: 0.0642 - acc: 0.9974 - val_loss: 0.0818 - val_acc: 0.9942\n",
            "Epoch 192/200\n",
            "1541/1541 [==============================] - 0s 187us/step - loss: 0.0617 - acc: 0.9974 - val_loss: 0.0960 - val_acc: 0.9767\n",
            "Epoch 193/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0625 - acc: 0.9968 - val_loss: 0.1241 - val_acc: 0.9884\n",
            "Epoch 194/200\n",
            "1541/1541 [==============================] - 0s 190us/step - loss: 0.0676 - acc: 0.9955 - val_loss: 0.0694 - val_acc: 0.9942\n",
            "Epoch 195/200\n",
            "1541/1541 [==============================] - 0s 188us/step - loss: 0.0630 - acc: 0.9968 - val_loss: 0.0766 - val_acc: 0.9826\n",
            "Epoch 196/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0610 - acc: 0.9981 - val_loss: 0.0940 - val_acc: 0.9942\n",
            "Epoch 197/200\n",
            "1541/1541 [==============================] - 0s 192us/step - loss: 0.0727 - acc: 0.9929 - val_loss: 0.1456 - val_acc: 0.9767\n",
            "Epoch 198/200\n",
            "1541/1541 [==============================] - 0s 197us/step - loss: 0.0811 - acc: 0.9903 - val_loss: 0.1356 - val_acc: 0.9709\n",
            "Epoch 199/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0970 - acc: 0.9851 - val_loss: 0.2011 - val_acc: 0.9709\n",
            "Epoch 200/200\n",
            "1541/1541 [==============================] - 0s 194us/step - loss: 0.0966 - acc: 0.9857 - val_loss: 0.1753 - val_acc: 0.9767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZkxx0gN3811",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "classes=[\"dog\", \"clock alarm\", \"glass breaking\", \"fireworks\", \"clapping\", \"door knock\"]\n",
        "\n",
        "\n",
        "real_label_batch = tf.argmax(y_test_hot, axis=1)\n",
        "y_pred=model.predict_classes(X_test)\n",
        "con_mat = tf.math.confusion_matrix(labels=real_label_batch, predictions=y_pred).numpy()   \n",
        "\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "                     index = classes, \n",
        "                     columns = classes)\n",
        "\n",
        "figure = plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "tf.compat.v1.logging.info('Confusion Matrix:\\n %s' % (con_mat))\n",
        "tf.compat.v1.logging.info('Confusion Matrix Normalized:\\n %s' % (con_mat_norm))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xpKJkDn-ict",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating model graphically\n",
        "Accuracy graph and loss graph of both training and validation.\n",
        "This allows me to see if data is overfitting after a number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yklwi1jWbIYR",
        "colab_type": "code",
        "outputId": "5c5dbbae-8755-421d-d133-d1c17de54226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs,val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAELCAYAAADTK53JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T8deeyfb3FIoQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAELCAYAAADTK53JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npS7lIMQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpdOuXb6bYqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "324a20c5-e649-4030-a173-7515a7e59d18"
      },
      "source": [
        "eval_speech_graph = tf.Graph()\n",
        "eval_speech_sess = tf.Session(graph=eval_speech_graph)\n",
        "\n",
        "keras.backend.set_session(eval_speech_sess)\n",
        "with eval_speech_graph.as_default():\n",
        "    keras.backend.set_learning_phase(0)\n",
        "    eval_model = build_urban_model()\n",
        "\n",
        "    #For quantization aware training only\n",
        "    #tf.contrib.quantize.create_eval_graph(input_graph=eval_speech_graph)\n",
        "    eval_speech_graph_def = eval_speech_graph.as_graph_def()\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(eval_speech_sess, 'checkpoints')\n",
        "\n",
        "    frozen_graph_def = tf.graph_util.convert_variables_to_constants( eval_speech_sess, eval_speech_graph_def, \n",
        "                                                                    [eval_model.output.op.name] )\n",
        "\n",
        "    with open('frozen_urban_model.pb', 'wb') as f:\n",
        "      f.write(frozen_graph_def.SerializeToString())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from checkpoints\n",
            "WARNING:tensorflow:From <ipython-input-63-0f3293bd894d>:16: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 22 variables.\n",
            "INFO:tensorflow:Converted 22 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08hKd54EbcZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph( \"frozen_urban_model.pb\", [\"conv2d_1_input\"], [\"dense_2/Softmax\"])\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIlBwXKwbggT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tflite_models_dir = pathlib.Path(\"/tmp/ESC50-split-models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNrAu1U9bji8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e146438c-a53c-4f63-a755-255a6c8b21f3"
      },
      "source": [
        "tflite_model_file = tflite_models_dir/\"esc50-split-model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "692348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-X6HfpTbp-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1f43ae61-3337-4cd8-9a77-c63f4e27eed6"
      },
      "source": [
        "!ls -lh {tflite_models_dir}"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 680K\n",
            "-rw-r--r-- 1 root root 677K Nov 17 08:14 esc50-split-model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM3mB_NXbtcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimize for size\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JntPYN4Hb1GK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create quantized values with an accurate dynamic range of activations, \n",
        "# for that need to provide a representative dataset\n",
        "\n",
        "#sounds = tf.cast(X_train, tf.float32)/1000.0\n",
        "sounds = tf.cast(X_train, tf.float32)\n",
        "urban_ds = tf.data.Dataset.from_tensor_slices((sounds)).batch(1)\n",
        "def representative_data_gen():\n",
        "  for input_value in urban_ds.take(100):\n",
        "    yield [input_value]\n",
        "    \n",
        "converter.representative_dataset = representative_data_gen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1THqf2Vb7BK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60aac929-8e61-44f3-f7ca-c0b138164112"
      },
      "source": [
        "# tflite format quantized\n",
        "tflite_quant_model = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"esc50-split-model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Onr0wC4b9c4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b7cc44d5-14fc-446c-c1c8-0bd1d592a842"
      },
      "source": [
        "!ls -lh {tflite_models_dir}"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 888K\n",
            "-rw-r--r-- 1 root root 206K Nov 17 08:14 esc50-split-model_quant.tflite\n",
            "-rw-r--r-- 1 root root 677K Nov 17 08:14 esc50-split-model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXAtbUgcDN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fbd7c17-107c-4cb3-ae19-fa066f111d24"
      },
      "source": [
        "# The converted model needs to be fully quantized. That means all ops need to be \n",
        "# quantized, no floats left. The input and outputs need to be integers too.\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"esc50-split-model_quant_io.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4ytwLYcFbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "54fc145b-257a-48f3-b825-b0d57b9f0d4c"
      },
      "source": [
        "!ls -lh {tflite_models_dir}"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.1M\n",
            "-rw-r--r-- 1 root root 206K Nov 17 08:15 esc50-split-model_quant_io.tflite\n",
            "-rw-r--r-- 1 root root 206K Nov 17 08:14 esc50-split-model_quant.tflite\n",
            "-rw-r--r-- 1 root root 677K Nov 17 08:14 esc50-split-model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Kl7JSCcIzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fe7b6bd1-8a0c-4f4f-d650-49423fd896df"
      },
      "source": [
        "# Load data for float model\n",
        "sounds = tf.cast(X_test, tf.float32)\n",
        "urban_ds = tf.data.Dataset.from_tensor_slices(sounds).batch(1)\n",
        "\n",
        "\n",
        "X_train_flat = X_train.flatten()\n",
        "X_train_max = max(X_train_flat)\n",
        "X_train_min = min(X_train_flat)\n",
        "print(X_train_max)\n",
        "print(X_train_min)\n",
        "\n",
        "\n",
        "# Load data for quantized model\n",
        "X_test_flat = X_test.flatten()\n",
        "X_test_max = max(X_test_flat)\n",
        "X_test_min = min(X_test_flat)\n",
        "print(X_test_max)\n",
        "print(X_test_min)\n",
        "quant_sounds = tf.quantization.quantize(X_test, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "#quant_sounds = tf.quantization.quantize(X_test, X_test_min, X_test_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "sounds_uint8 = tf.cast(quant_sounds[0], tf.uint8)\n",
        "urban_ds_uint8 = tf.data.Dataset.from_tensor_slices(sounds_uint8).batch(1)\n",
        "\n",
        "#print(sounds_uint8)\n",
        "#print(X_test)\n",
        "#print(quant_sounds[0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "291.0303548297577\n",
            "-753.7850166427609\n",
            "264.9247658348073\n",
            "-754.1781114287814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4UnJAdcWLh",
        "colab_type": "text"
      },
      "source": [
        "### run model with tflite interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcZsguVKbvrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(records, n):\n",
        "  max = records[0]\n",
        "  \n",
        "  for i in range(1, n):\n",
        "    if records[i] > max:\n",
        "      max = records[i]\n",
        "\n",
        "  index = record.index(max)\n",
        "\n",
        "  return max, index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG7zJCgGcf2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZkm68iJcifv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBxZkovAclXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05ee8cd0-a449-4a31-c29f-c49a43462229"
      },
      "source": [
        "labels=['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
        "\n",
        "for m in range(11, 30):\n",
        "  print(\"\\nRunning number\", m)\n",
        "  predict_number = m\n",
        "\n",
        "  i=0\n",
        "  for sound in urban_ds:\n",
        "    #for list in sound:\n",
        "      \n",
        "      #break\n",
        "    if i == predict_number:\n",
        "      break\n",
        "    i= i+1\n",
        "    \n",
        "    #print(list[1])\n",
        "\n",
        "  #print(sound.shape)\n",
        "  #print(list.shape)\n",
        "  interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], sound)\n",
        "  interpreter.invoke()\n",
        "  predictions = interpreter.get_tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "  print(predictions)\n",
        "\n",
        "  class_prediction = predictions.tolist()\n",
        "\n",
        "  for record in class_prediction:\n",
        "    record\n",
        "\n",
        "  records = array(record)\n",
        "\n",
        "  n = len(records)\n",
        "\n",
        "  class_predicted, indice = predict(records, n)\n",
        "\n",
        "  real_words = y_test[predict_number]\n",
        "  real_word = int(real_words)\n",
        "  word_predicted = labels[indice]\n",
        "\n",
        "  print(labels)\n",
        "  print(\"\\nFLOATS\")\n",
        "  print('---------------------')\n",
        "  print('Predicted class is ', labels[indice])\n",
        "  print('Real class is ', labels[real_word])\n",
        "  print('----------------------\\n\\n')  \n",
        "\n",
        "\n",
        "  i=0\n",
        "  for sound in urban_ds_uint8:\n",
        "    \n",
        "    if i == predict_number:\n",
        "      break\n",
        "    i= i+1\n",
        "  #print(sound)\n",
        "  interpreter_quant.set_tensor(interpreter_quant.get_input_details()[0][\"index\"], sound)\n",
        "  interpreter_quant.invoke()\n",
        "  predictions = interpreter_quant.get_tensor(\n",
        "      interpreter_quant.get_output_details()[0][\"index\"])\n",
        "\n",
        "  class_prediction = predictions.tolist()\n",
        "\n",
        "  for record in class_prediction:\n",
        "    record\n",
        "\n",
        "  records = array(record)\n",
        "\n",
        "  n = len(records)\n",
        "\n",
        "  class_predicted, indice = predict(records, n)\n",
        "\n",
        "  print(predictions)\n",
        "\n",
        "  print(\"\\n\\nINTEGERS\")\n",
        "  print(\"---------------------------\")\n",
        "\n",
        "  print('Predicted class is ', labels[indice])\n",
        "  print('Real class is ', labels[real_word])\n",
        "  print('----------------------------') \n",
        "\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running number 11\n",
            "[[3.1219213e-34 3.0622054e-14 1.9150728e-11 1.8849014e-25 2.4951265e-33\n",
            "  1.0000000e+00]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0   0 255]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------------\n",
            "\n",
            "Running number 12\n",
            "[[1.0000000e+00 5.8158283e-35 3.3508080e-08 1.7404541e-37 4.6823058e-34\n",
            "  1.8812432e-40]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[255   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------------\n",
            "\n",
            "Running number 13\n",
            "[[1.8927884e-28 4.1878987e-12 1.7482410e-09 2.1991427e-21 1.3312357e-27\n",
            "  1.0000000e+00]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0   0 255]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------------\n",
            "\n",
            "Running number 14\n",
            "[[5.0579897e-20 5.5685170e-15 1.0000000e+00 4.7258234e-33 3.8999370e-18\n",
            "  9.5464183e-12]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  dog\n",
            "Real class is  dog\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0 255   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  dog\n",
            "Real class is  dog\n",
            "----------------------------\n",
            "\n",
            "Running number 15\n",
            "[[9.9995494e-01 6.2999105e-14 4.5030334e-05 3.6159443e-12 1.3350960e-13\n",
            "  1.0135737e-14]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[255   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------------\n",
            "\n",
            "Running number 16\n",
            "[[3.4713504e-16 6.8948327e-07 3.0646654e-05 9.4265524e-13 6.2130959e-15\n",
            "  9.9996865e-01]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0   0 255]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------------\n",
            "\n",
            "Running number 17\n",
            "[[2.9288539e-41 2.9033465e-16 3.1457726e-14 2.3038022e-29 4.2771833e-41\n",
            "  1.0000000e+00]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0   0 255]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------------\n",
            "\n",
            "Running number 18\n",
            "[[1.2257338e-07 3.8991857e-04 8.3126518e-04 2.1692754e-12 9.9877673e-01\n",
            "  1.9457934e-06]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  door knock\n",
            "Real class is  door knock\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0  13   0   0 243   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  door knock\n",
            "Real class is  door knock\n",
            "----------------------------\n",
            "\n",
            "Running number 19\n",
            "[[2.4115580e-19 3.4118802e-08 5.9317819e-07 5.9688033e-33 9.9999940e-01\n",
            "  3.2592807e-15]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  door knock\n",
            "Real class is  door knock\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0 255   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  door knock\n",
            "Real class is  door knock\n",
            "----------------------------\n",
            "\n",
            "Running number 20\n",
            "[[0.01275718 0.15399984 0.01652689 0.03151348 0.71707886 0.06812382]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  door knock\n",
            "Real class is  door knock\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0  72   0 150   0  34]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  glass breaking\n",
            "Real class is  door knock\n",
            "----------------------------\n",
            "\n",
            "Running number 21\n",
            "[[3.9871221e-17 6.4983840e-05 6.3183714e-10 1.6252547e-05 7.8266787e-18\n",
            "  9.9991870e-01]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0   0   0 255]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  clapping\n",
            "----------------------------\n",
            "\n",
            "Running number 22\n",
            "[[2.2247945e-05 9.1296381e-01 2.4687473e-04 6.2699705e-02 7.1890530e-04\n",
            "  2.3348523e-02]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  glass breaking\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0 252   0   1   1   1]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  glass breaking\n",
            "----------------------------\n",
            "\n",
            "Running number 23\n",
            "[[1.8252903e-10 9.9992609e-01 3.6647711e-07 3.2410312e-09 7.3132083e-05\n",
            "  3.6482109e-07]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  fireworks\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0 255   0   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  fireworks\n",
            "----------------------------\n",
            "\n",
            "Running number 24\n",
            "[[9.9962366e-01 3.3258091e-11 3.7635310e-04 6.2765387e-10 9.8758834e-11\n",
            "  7.8706434e-12]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[253   0   3   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------------\n",
            "\n",
            "Running number 25\n",
            "[[5.8321547e-07 3.7441894e-02 5.7579945e-07 9.6061862e-01 4.1681486e-07\n",
            "  1.9378359e-03]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  glass breaking\n",
            "Real class is  glass breaking\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0  21   0  44   0 191]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clapping\n",
            "Real class is  glass breaking\n",
            "----------------------------\n",
            "\n",
            "Running number 26\n",
            "[[2.84738514e-13 1.18095382e-08 1.00000000e+00 2.97683762e-24\n",
            "  6.40297726e-09 1.08698835e-10]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  dog\n",
            "Real class is  dog\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0 255   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  dog\n",
            "Real class is  dog\n",
            "----------------------------\n",
            "\n",
            "Running number 27\n",
            "[[2.2895375e-14 9.9999928e-01 3.1425717e-08 1.9799782e-11 7.2560482e-08\n",
            "  5.6319516e-07]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  fireworks\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0 255   0   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  fireworks\n",
            "Real class is  fireworks\n",
            "----------------------------\n",
            "\n",
            "Running number 28\n",
            "[[9.9992645e-01 2.3111697e-12 7.3498835e-05 5.4550708e-11 1.4665890e-11\n",
            "  3.9177616e-13]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[255   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  clock alarm\n",
            "Real class is  clock alarm\n",
            "----------------------------\n",
            "\n",
            "Running number 29\n",
            "[[4.3568832e-10 8.1973738e-04 5.9941951e-10 9.9892706e-01 2.8109327e-11\n",
            "  2.5311217e-04]]\n",
            "['clock alarm', 'fireworks', 'dog', 'glass breaking', 'door knock', 'clapping']\n",
            "\n",
            "FLOATS\n",
            "---------------------\n",
            "Predicted class is  glass breaking\n",
            "Real class is  glass breaking\n",
            "----------------------\n",
            "\n",
            "\n",
            "[[  0   0   0 255   0   0]]\n",
            "\n",
            "\n",
            "INTEGERS\n",
            "---------------------------\n",
            "Predicted class is  glass breaking\n",
            "Real class is  glass breaking\n",
            "----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltCdABhHqRs",
        "colab_type": "text"
      },
      "source": [
        "# Test data preparation\n",
        "This prepares single files never seen by model.\n",
        "This files are used on other targets to test model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5DYXAjcqoOk",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the test files based on the dataset distribution worked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78nIx_T6cYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_data = np.mean(X)\n",
        "sdt_dev_data = np.std(X)\n",
        "\n",
        "# test file set 1\n",
        "mfcc_clapping1 = urban_wav2mfcc('test_single_file/clapping/clapping-E-2-25292-A.wav', max_pad_len=51)\n",
        "mfcc_dog1 = urban_wav2mfcc('test_single_file/dog/dog-A-5-208030-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock1 = urban_wav2mfcc('test_single_file/door_knock/door_knock-A-2-133889-A.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm1 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-A-2-104476-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking1 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-A-1-88807-A.wav', max_pad_len=51)\n",
        "mfcc_fireworks1 = urban_wav2mfcc('test_single_file/fireworks/fireworks-A-2-117615-D.wav', max_pad_len=51)\n",
        "\n",
        "\n",
        "\n",
        "mfcc_clapping1_std = normalize_data(mfcc_clapping1, mean_data, sdt_dev_data )\n",
        "mfcc_dog1_std = normalize_data(mfcc_dog1, mean_data, sdt_dev_data )\n",
        "mfcc_door_knock1_std = normalize_data(mfcc_door_knock1, mean_data, sdt_dev_data )\n",
        "mfcc_clock_alarm1_std = normalize_data(mfcc_clock_alarm1, mean_data, sdt_dev_data )\n",
        "mfcc_glass_breaking1_std = normalize_data(mfcc_glass_breaking1 , mean_data, sdt_dev_data )\n",
        "mfcc_fireworks1_std = normalize_data(mfcc_fireworks1, mean_data, sdt_dev_data )\n",
        "\n",
        "\n",
        "\n",
        "clapping_file1 = mfcc_clapping1_std.reshape(1, MFCC, 51, 1)\n",
        "dog_file1 = mfcc_dog1_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file1 = mfcc_door_knock1_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file1 = mfcc_clock_alarm1_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file1 = mfcc_glass_breaking1_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file1 = mfcc_fireworks1_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'clapping_single1.npy', clapping_file1)\n",
        "np.save('/content/' + 'dog_single1.npy', dog_file1)\n",
        "np.save('/content/' + 'door_knock_single1.npy', door_knock_file1 )\n",
        "np.save('/content/' + 'clock_alarm_single1.npy', clock_alarm_file1 )\n",
        "np.save('/content/' + 'glass_breaking_single1.npy', glass_breaking_file1)\n",
        "np.save('/content/' + 'fireworks_single1.npy', fireworks_file1)\n",
        "\n",
        "\n",
        "\n",
        "# test file set 2\n",
        "mfcc_clapping2 = urban_wav2mfcc('test_single_file/clapping/clapping-E-3-177082-A.wav', max_pad_len=51)\n",
        "mfcc_dog2 = urban_wav2mfcc('test_single_file/dog/dog-E-3-144028-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock2 = urban_wav2mfcc('test_single_file/door_knock/door_knock-A-5-250026-B.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm2 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-B-3-117883-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking2 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-A-4-212698-A.wav', max_pad_len=51)\n",
        "mfcc_fireworks2 = urban_wav2mfcc('test_single_file/fireworks/fireworks-A-4-119648-A.wav', max_pad_len=51)\n",
        "\n",
        "\n",
        "mfcc_clapping2_std = normalize_data(mfcc_clapping2, mean_data, sdt_dev_data )\n",
        "mfcc_dog2_std = normalize_data(mfcc_dog2, mean_data, sdt_dev_data )\n",
        "mfcc_door_knock2_std = normalize_data(mfcc_door_knock2, mean_data, sdt_dev_data )\n",
        "mfcc_clock_alarm2_std = normalize_data(mfcc_clock_alarm2, mean_data, sdt_dev_data )\n",
        "mfcc_glass_breaking2_std = normalize_data(mfcc_glass_breaking2 , mean_data, sdt_dev_data )\n",
        "mfcc_fireworks2_std = normalize_data(mfcc_fireworks2, mean_data, sdt_dev_data )\n",
        "\n",
        "\n",
        "dog_file2 = mfcc_dog2_std.reshape(1, MFCC, 51, 1)\n",
        "clapping_file2 = mfcc_clapping2_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file2 = mfcc_door_knock2_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file2 = mfcc_clock_alarm2_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file2 = mfcc_glass_breaking2_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file2 = mfcc_fireworks2_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single2.npy', dog_file2)\n",
        "np.save('/content/' + 'clapping_single2.npy', clapping_file2)\n",
        "np.save('/content/' + 'door_knock_single2.npy', door_knock_file2 )\n",
        "np.save('/content/' + 'clock_alarm_single2.npy', clock_alarm_file2 )\n",
        "np.save('/content/' + 'glass_breaking_single2.npy', glass_breaking_file2)\n",
        "np.save('/content/' + 'fireworks_single2.npy', fireworks_file2)\n",
        "\n",
        "\n",
        "\n",
        "# test file set 3\n",
        "mfcc_clapping3 = urban_wav2mfcc('test_single_file/clapping/clapping-E-4-189828-A.wav', max_pad_len=51)\n",
        "mfcc_dog3 = urban_wav2mfcc('test_single_file/dog/dog-D-5-208030-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock3 = urban_wav2mfcc('test_single_file/door_knock/door_knock-B-1-101336-A.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm3 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-B-3-132340-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking3 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-B-4-204777-B.wav', max_pad_len=51)\n",
        "mfcc_fireworks3 = urban_wav2mfcc('test_single_file/fireworks/fireworks-E-2-117617-A.wav', max_pad_len=51)\n",
        "\n",
        "\n",
        "mfcc_clapping3_std = normalize_data(mfcc_clapping3, mean_data, sdt_dev_data )\n",
        "mfcc_dog3_std = normalize_data(mfcc_dog3, mean_data, sdt_dev_data )\n",
        "mfcc_door_knock3_std = normalize_data(mfcc_door_knock3, mean_data, sdt_dev_data )\n",
        "mfcc_clock_alarm3_std = normalize_data(mfcc_clock_alarm3, mean_data, sdt_dev_data )\n",
        "mfcc_glass_breaking3_std = normalize_data(mfcc_glass_breaking3 , mean_data, sdt_dev_data )\n",
        "mfcc_fireworks3_std = normalize_data(mfcc_fireworks3, mean_data, sdt_dev_data )\n",
        "\n",
        "\n",
        "dog_file3 = mfcc_dog3_std.reshape(1, MFCC, 51, 1)\n",
        "clapping_file3 = mfcc_clapping3_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file3 = mfcc_door_knock3_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file3 = mfcc_clock_alarm3_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file3 = mfcc_glass_breaking3_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file3 = mfcc_fireworks3_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single3.npy', dog_file3)\n",
        "np.save('/content/' + 'clapping_single3.npy', clapping_file3)\n",
        "np.save('/content/' + 'door_knock_single3.npy', door_knock_file3 )\n",
        "np.save('/content/' + 'clock_alarm_single3.npy', clock_alarm_file3 )\n",
        "np.save('/content/' + 'glass_breaking_single3.npy', glass_breaking_file3)\n",
        "np.save('/content/' + 'fireworks_single3.npy', fireworks_file3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YaiWxiLurVu",
        "colab_type": "text"
      },
      "source": [
        "### The test files worked with dataset distribution parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP8ZpXQEV5Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data1\n",
        "dog_flat = dog_file1.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_1 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file1.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_1 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file1.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_1 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file1.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_1 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file1.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_1 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file1.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file1, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_1 = tf.cast(quant_fireworks[0], tf.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#data2\n",
        "dog_flat = dog_file2.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_2 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file2.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_2 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file2.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_2 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file2.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_2 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file2.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_2 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file2.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file2, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_2 = tf.cast(quant_fireworks[0], tf.uint8)\n",
        "\n",
        "\n",
        "\n",
        "#data3\n",
        "dog_flat = dog_file3.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file3, X_train_min, dog_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_3 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file3.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file3, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_3 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file3.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file3, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_3 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file3.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file3, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_3 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file3.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file3, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_3 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file3.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file3, X_train_min, X_train_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_3 = tf.cast(quant_fireworks[0], tf.uint8)                                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Petes4Fvxb4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/' + 'dog_single_uint8_1.npy', dog_uint8_1)\n",
        "np.save('/content/' + 'clapping_single_uint8_1.npy', clapping_uint8_1)\n",
        "np.save('/content/' + 'door_knock_single_uint8_1.npy', door_knock_uint8_1)\n",
        "np.save('/content/' + 'clock_alarm_single_uint8_1.npy', clock_alarm_uint8_1 )\n",
        "np.save('/content/' + 'glass_breaking_single_uint8_1.npy', glass_breaking_uint8_1)\n",
        "np.save('/content/' + 'fireworks_single_uint8_1.npy', fireworks_uint8_1 )\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single_uint8_2.npy', dog_uint8_2)\n",
        "np.save('/content/' + 'clapping_single_uint8_2.npy', clapping_uint8_2)\n",
        "np.save('/content/' + 'door_knock_single_uint8_2.npy', door_knock_uint8_2)\n",
        "np.save('/content/' + 'clock_alarm_single_uint8_2.npy', clock_alarm_uint8_2 )\n",
        "np.save('/content/' + 'glass_breaking_single_uint8_2.npy', glass_breaking_uint8_2)\n",
        "np.save('/content/' + 'fireworks_single_uint8_2.npy', fireworks_uint8_2 )\n",
        "\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single_uint8_3.npy', dog_uint8_3)\n",
        "np.save('/content/' + 'clapping_single_uint8_3.npy', clapping_uint8_3)\n",
        "np.save('/content/' + 'door_knock_single_uint8_3.npy', door_knock_uint8_3)\n",
        "np.save('/content/' + 'clock_alarm_single_uint8_3.npy', clock_alarm_uint8_3 )\n",
        "np.save('/content/' + 'glass_breaking_single_uint8_3.npy', glass_breaking_uint8_3)\n",
        "np.save('/content/' + 'fireworks_single_uint8_3.npy', fireworks_uint8_3 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZZ7vF7gHe8s",
        "colab_type": "text"
      },
      "source": [
        "## Bad test data \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGtCsLp9qZZ0",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the test files individually did not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIvAq61Ttd61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mean_data = np.mean(X)\n",
        "#sdt_dev_data = np.std(X)\n",
        "\n",
        "\n",
        "# test file set 1\n",
        "mfcc_clapping1 = urban_wav2mfcc('test_single_file/clapping/clapping-E-2-25292-A.wav', max_pad_len=51)\n",
        "mfcc_dog1 = urban_wav2mfcc('test_single_file/dog/dog-A-5-208030-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock1 = urban_wav2mfcc('test_single_file/door_knock/door_knock-A-2-133889-A.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm1 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-A-2-104476-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking1 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-A-1-88807-A.wav', max_pad_len=51)\n",
        "mfcc_fireworks1 = urban_wav2mfcc('test_single_file/fireworks/fireworks-A-2-117615-D.wav', max_pad_len=51)\n",
        "\n",
        "# MEAN set 1\n",
        "clapping1_mean = np.mean(mfcc_clapping1)\n",
        "dog1_mean = np.mean(mfcc_dog1)\n",
        "door_knock1_mean = np.mean(mfcc_door_knock1)\n",
        "clock_alarm1_mean = np.mean(mfcc_clock_alarm1)\n",
        "glass_breaking1_mean = np.mean(mfcc_glass_breaking1)\n",
        "fireworks1_mean = np.mean(mfcc_fireworks1)\n",
        "\n",
        "#STANDARD DEVIATION set 1\n",
        "clapping1_std = np.std(mfcc_clapping1)\n",
        "dog1_std = np.std(mfcc_dog1)\n",
        "door_knock1_std = np.std(mfcc_door_knock1)\n",
        "clock_alarm1_std = np.std(mfcc_clock_alarm1)\n",
        "glass_breaking1_std = np.std(mfcc_glass_breaking1)\n",
        "fireworks1_std = np.std(mfcc_fireworks1)\n",
        "\n",
        "\n",
        "\n",
        "mfcc_clapping1_std = normalize_data(mfcc_clapping1, clapping1_mean, clapping1_std )\n",
        "mfcc_dog1_std = normalize_data(mfcc_dog1, dog1_mean, dog1_std )\n",
        "mfcc_door_knock1_std = normalize_data(mfcc_door_knock1, door_knock1_mean, door_knock1_std  )\n",
        "mfcc_clock_alarm1_std = normalize_data(mfcc_clock_alarm1, clock_alarm1_mean, clock_alarm1_std )\n",
        "mfcc_glass_breaking1_std = normalize_data(mfcc_glass_breaking1 , glass_breaking1_mean, glass_breaking1_std )\n",
        "mfcc_fireworks1_std = normalize_data(mfcc_fireworks1, fireworks1_mean, fireworks1_std )\n",
        "\n",
        "\n",
        "\n",
        "clapping_file1 = mfcc_clapping1_std.reshape(1, MFCC, 51, 1)\n",
        "dog_file1 = mfcc_dog1_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file1 = mfcc_door_knock1_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file1 = mfcc_clock_alarm1_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file1 = mfcc_glass_breaking1_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file1 = mfcc_fireworks1_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'clapping_single1.npy', clapping_file1)\n",
        "np.save('/content/' + 'dog_single1.npy', dog_file1)\n",
        "np.save('/content/' + 'door_knock_single1.npy', door_knock_file1 )\n",
        "np.save('/content/' + 'clock_alarm_single1.npy', clock_alarm_file1 )\n",
        "np.save('/content/' + 'glass_breaking_single1.npy', glass_breaking_file1)\n",
        "np.save('/content/' + 'fireworks_single1.npy', fireworks_file1)\n",
        "\n",
        "\n",
        "\n",
        "# test file set 2\n",
        "mfcc_clapping2 = urban_wav2mfcc('test_single_file/clapping/clapping-E-3-177082-A.wav', max_pad_len=51)\n",
        "mfcc_dog2 = urban_wav2mfcc('test_single_file/dog/dog-E-3-144028-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock2 = urban_wav2mfcc('test_single_file/door_knock/door_knock-A-5-250026-B.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm2 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-B-3-117883-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking2 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-A-4-212698-A.wav', max_pad_len=51)\n",
        "mfcc_fireworks2 = urban_wav2mfcc('test_single_file/fireworks/fireworks-A-4-119648-A.wav', max_pad_len=51)\n",
        "\n",
        "\n",
        "# MEAN set 2\n",
        "clapping2_mean = np.mean(mfcc_clapping2)\n",
        "dog2_mean = np.mean(mfcc_dog2)\n",
        "door_knock2_mean = np.mean(mfcc_door_knock2)\n",
        "clock_alarm2_mean = np.mean(mfcc_clock_alarm2)\n",
        "glass_breaking2_mean = np.mean(mfcc_glass_breaking2)\n",
        "fireworks2_mean = np.mean(mfcc_fireworks2)\n",
        "\n",
        "#STANDARD DEVIATION set 2\n",
        "clapping2_std = np.std(mfcc_clapping2)\n",
        "dog2_std = np.std(mfcc_dog2)\n",
        "door_knock2_std = np.std(mfcc_door_knock2)\n",
        "clock_alarm2_std = np.std(mfcc_clock_alarm2)\n",
        "glass_breaking2_std = np.std(mfcc_glass_breaking2)\n",
        "fireworks2_std = np.std(mfcc_fireworks2)\n",
        "\n",
        "\n",
        "\n",
        "mfcc_clapping2_std = normalize_data(mfcc_clapping2, clapping2_mean, clapping2_std )\n",
        "mfcc_dog2_std = normalize_data(mfcc_dog2, dog2_mean, dog2_std )\n",
        "mfcc_door_knock2_std = normalize_data(mfcc_door_knock2, door_knock2_mean, door_knock2_std  )\n",
        "mfcc_clock_alarm2_std = normalize_data(mfcc_clock_alarm2, clock_alarm2_mean, clock_alarm2_std )\n",
        "mfcc_glass_breaking2_std = normalize_data(mfcc_glass_breaking2 , glass_breaking2_mean, glass_breaking2_std )\n",
        "mfcc_fireworks2_std = normalize_data(mfcc_fireworks2, fireworks2_mean, fireworks2_std )\n",
        "\n",
        "\n",
        "\n",
        "dog_file2 = mfcc_dog2_std.reshape(1, MFCC, 51, 1)\n",
        "clapping_file2 = mfcc_clapping2_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file2 = mfcc_door_knock2_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file2 = mfcc_clock_alarm2_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file2 = mfcc_glass_breaking2_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file2 = mfcc_fireworks2_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single2.npy', dog_file2)\n",
        "np.save('/content/' + 'clapping_single2.npy', clapping_file2)\n",
        "np.save('/content/' + 'door_knock_single2.npy', door_knock_file2 )\n",
        "np.save('/content/' + 'clock_alarm_single2.npy', clock_alarm_file2 )\n",
        "np.save('/content/' + 'glass_breaking_single2.npy', glass_breaking_file2)\n",
        "np.save('/content/' + 'fireworks_single2.npy', fireworks_file2)\n",
        "\n",
        "\n",
        "\n",
        "# test file set 3\n",
        "mfcc_clapping3 = urban_wav2mfcc('test_single_file/clapping/clapping-E-4-189828-A.wav', max_pad_len=51)\n",
        "mfcc_dog3 = urban_wav2mfcc('test_single_file/dog/dog-D-5-208030-A.wav', max_pad_len=51)\n",
        "mfcc_door_knock3 = urban_wav2mfcc('test_single_file/door_knock/door_knock-B-1-101336-A.wav', max_pad_len=51)\n",
        "mfcc_clock_alarm3 = urban_wav2mfcc('test_single_file/clock_alarm/clock_alarm-B-3-132340-A.wav', max_pad_len=51)\n",
        "mfcc_glass_breaking3 = urban_wav2mfcc('test_single_file/glass_breaking/glass_breaking-B-4-204777-B.wav', max_pad_len=51)\n",
        "mfcc_fireworks3 = urban_wav2mfcc('test_single_file/fireworks/fireworks-E-2-117617-A.wav', max_pad_len=51)\n",
        "\n",
        "\n",
        "# MEAN set 3\n",
        "clapping3_mean = np.mean(mfcc_clapping3)\n",
        "dog3_mean = np.mean(mfcc_dog3)\n",
        "door_knock3_mean = np.mean(mfcc_door_knock3)\n",
        "clock_alarm3_mean = np.mean(mfcc_clock_alarm3)\n",
        "glass_breaking3_mean = np.mean(mfcc_glass_breaking3)\n",
        "fireworks3_mean = np.mean(mfcc_fireworks3)\n",
        "\n",
        "#STANDARD DEVIATION set3\n",
        "clapping3_std = np.std(mfcc_clapping3)\n",
        "dog3_std = np.std(mfcc_dog3)\n",
        "door_knock3_std = np.std(mfcc_door_knock3)\n",
        "clock_alarm3_std = np.std(mfcc_clock_alarm3)\n",
        "glass_breaking3_std = np.std(mfcc_glass_breaking3)\n",
        "fireworks3_std = np.std(mfcc_fireworks3)\n",
        "\n",
        "\n",
        "mfcc_clapping3_std = normalize_data(mfcc_clapping3, clapping3_mean, clapping3_std )\n",
        "mfcc_dog3_std = normalize_data(mfcc_dog3, dog3_mean, dog3_std )\n",
        "mfcc_door_knock3_std = normalize_data(mfcc_door_knock3, door_knock3_mean, door_knock3_std)\n",
        "mfcc_clock_alarm3_std = normalize_data(mfcc_clock_alarm3, clock_alarm3_mean, clock_alarm3_std )\n",
        "mfcc_glass_breaking3_std = normalize_data(mfcc_glass_breaking3 , glass_breaking3_mean , glass_breaking3_std)\n",
        "mfcc_fireworks3_std = normalize_data(mfcc_fireworks3, fireworks3_mean, fireworks3_std )\n",
        "\n",
        "\n",
        "dog_file3 = mfcc_dog3_std.reshape(1, MFCC, 51, 1)\n",
        "clapping_file3 = mfcc_clapping3_std.reshape(1, MFCC, 51, 1)\n",
        "door_knock_file3 = mfcc_door_knock3_std.reshape(1, MFCC, 51, 1)\n",
        "clock_alarm_file3 = mfcc_clock_alarm3_std.reshape(1, MFCC, 51, 1)\n",
        "glass_breaking_file3 = mfcc_glass_breaking3_std.reshape(1, MFCC, 51, 1)\n",
        "fireworks_file3 = mfcc_fireworks3_std.reshape(1, MFCC, 51, 1)\n",
        "\n",
        "\n",
        "np.save('/content/' + 'dog_single3.npy', dog_file3)\n",
        "np.save('/content/' + 'clapping_single3.npy', clapping_file3)\n",
        "np.save('/content/' + 'door_knock_single3.npy', door_knock_file3 )\n",
        "np.save('/content/' + 'clock_alarm_single3.npy', clock_alarm_file3 )\n",
        "np.save('/content/' + 'glass_breaking_single3.npy', glass_breaking_file3)\n",
        "np.save('/content/' + 'fireworks_single3.npy', fireworks_file3)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaW750KXuhkn",
        "colab_type": "text"
      },
      "source": [
        "### The test files normalized individually did not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33pF54SYwBwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data1\n",
        "dog_flat = dog_file1.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file1, dog_min, dog_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_1 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file1.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file1, clapping_min, clapping_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_1 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file1.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file1, door_knock_min , door_knock_max , tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_1 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file1.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file1, clock_alarm_min, clock_alarm_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_1 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file1.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file1, glass_breaking_min, glass_breaking_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_1 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file1.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file1, fireworks_min, fireworks_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_1 = tf.cast(quant_fireworks[0], tf.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#data2\n",
        "dog_flat = dog_file2.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file2, dog_min, dog_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_2 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file2.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file2, clapping_min, clapping_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_2 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file2.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file2, door_knock_min, door_knock_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_2 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file2.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file2, clock_alarm_min, clock_alarm_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_2 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file2.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file2, glass_breaking_min, glass_breaking_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_2 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file2.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file2, fireworks_min, fireworks_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_2 = tf.cast(quant_fireworks[0], tf.uint8)\n",
        "\n",
        "\n",
        "\n",
        "#data3\n",
        "dog_flat = dog_file3.flatten()\n",
        "dog_min = min(dog_flat)\n",
        "dog_max = max(dog_flat)\n",
        "quant_dog = tf.quantization.quantize(dog_file3, dog_min, dog_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "dog_uint8_3 = tf.cast(quant_dog[0], tf.uint8)\n",
        "\n",
        "clapping_flat = clapping_file3.flatten()\n",
        "clapping_min = min(clapping_flat)\n",
        "clapping_max = max(clapping_flat)\n",
        "quant_clapping = tf.quantization.quantize(clapping_file3, clapping_min, clapping_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clapping_uint8_3 = tf.cast(quant_clapping[0], tf.uint8)\n",
        "\n",
        "door_knock_flat = door_knock_file3.flatten()\n",
        "door_knock_min = min(door_knock_flat)\n",
        "door_knock_max = max(door_knock_flat)\n",
        "quant_door_knock = tf.quantization.quantize(door_knock_file3, door_knock_min, door_knock_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "door_knock_uint8_3 = tf.cast(quant_door_knock[0], tf.uint8)\n",
        "\n",
        "clock_alarm_flat = clock_alarm_file3.flatten()\n",
        "clock_alarm_min = min(clock_alarm_flat)\n",
        "clock_alarm_max = max(clock_alarm_flat)\n",
        "quant_clock_alarm = tf.quantization.quantize(clock_alarm_file3, clock_alarm_min, clock_alarm_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "clock_alarm_uint8_3 = tf.cast(quant_clock_alarm[0], tf.uint8)\n",
        "\n",
        "glass_breaking_flat = glass_breaking_file3.flatten()\n",
        "glass_breaking_min = min(glass_breaking_flat)\n",
        "glass_breaking_max = max(glass_breaking_flat)\n",
        "quant_glass_breaking = tf.quantization.quantize(glass_breaking_file3, glass_breaking_min, glass_breaking_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "glass_breaking_uint8_3 = tf.cast(quant_glass_breaking[0], tf.uint8)\n",
        "\n",
        "fireworks_flat = fireworks_file3.flatten()\n",
        "fireworks_min = min(fireworks_flat)\n",
        "fireworks_max = max(fireworks_flat)\n",
        "quant_fireworks = tf.quantization.quantize(fireworks_file3, fireworks_min, fireworks_max, tf.quint8, mode=\"MIN_COMBINED\", round_mode=\"HALF_AWAY_FROM_ZERO\", name=None)\n",
        "fireworks_uint8_3 = tf.cast(quant_fireworks[0], tf.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}