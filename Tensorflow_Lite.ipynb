{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_Lite.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villasen/colab_notebooks/blob/master/Tensorflow_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b5XhntcHiIs",
        "colab_type": "text"
      },
      "source": [
        "# Creating And Running Tensorflow_lite model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMEWpFzm-sYV",
        "colab_type": "code",
        "outputId": "9315b771-2de1-4809-ec1e-c69fb8c3277e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/villasen/Sound-Datasets.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Sound-Datasets'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 30921 (delta 0), reused 2 (delta 0), pack-reused 30918\u001b[K\n",
            "Receiving objects: 100% (30921/30921), 1.70 GiB | 28.20 MiB/s, done.\n",
            "Resolving deltas: 100% (6140/6140), done.\n",
            "Checking out files: 100% (33680/33680), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSN7XaGYcRLI",
        "colab_type": "code",
        "outputId": "fb40e815-4ea0-498b-b047-23419a174230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/villasen/ML-KWS-for-MCU.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML-KWS-for-MCU' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJSK-vgGnJYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r ML-KWS-for-MCU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogLvhkzkPzB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMcm3yejaMNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/ML-KWS-for-MCU')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH3lLtDdb26f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w_82-dgeywD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import hashlib\n",
        "import math\n",
        "import os.path\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
        "from tensorflow.python.ops import io_ops\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.util import compat\n",
        "\n",
        "import argparse\n",
        "\n",
        "import input_data\n",
        "import models\n",
        "\n",
        "\n",
        "from tensorflow.python.platform import gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vHue_U64i3A_",
        "colab": {}
      },
      "source": [
        " def load_wav_file(filename):\n",
        "  with tf.Session(graph=tf.Graph()) as sess:\n",
        "    wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
        "    wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
        "    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\n",
        "    return sess.run(\n",
        "        wav_decoder,\n",
        "        feed_dict={wav_filename_placeholder: filename}).audio.flatten()\n",
        "  \n",
        "load_wav_file(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gdZ2x5_t1OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env FILE_PATH=Sound-Datasets/combined_datasets/Helicopter/1-172649-A.wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w8k6X_lh_bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ML-KWS-for-MCU/wav_to_features.py --window_size_ms 40.0 --window_stride_ms 20.0 --feature_bin_count 10 \\\n",
        "--input_wav $FILE_PATH --output_c_file wav_to_feat.c\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYCnZwlYoLk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python wav_to_features.py --window_size_ms 40.0 --window_stride_ms 20.0 --feature_bin_count 10 \\\n",
        "--input_wav $FILE_PATH --output_c_file wav_to_feat.c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVPZf2-Sn3E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_count=12\n",
        "sample_rate=16000\n",
        "clip_duration_ms=1000\n",
        "window_size_ms=40.0\n",
        "window_stride_ms=20.0\n",
        "feature_bin_count=10\n",
        "quantize=True\n",
        "preprocess='mfcc'\n",
        "input_wav='0b7ee1a0_nohash_3.wav'\n",
        "output_c_file='done.c'\n",
        "\n",
        "\n",
        "# Start a new TensorFlow session.\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "\n",
        "model_settings = models.prepare_model_settings(\n",
        "      10, 16000, 1000, 40.0, 20.0, 10,'mfcc')\n",
        "\n",
        "#model_settings = models.prepare_model_settings(label_count, sample_rate,\n",
        "#                clip_duration_ms, window_size_ms, window_stride_ms,\n",
        "#               feature_bin_count, preprocess)\n",
        "\n",
        "#print(model_settings)\n",
        "\n",
        "audio_processor = input_data.AudioProcessor(None, None, 0, 0, '', 0, 0,\n",
        "                                              model_settings,None)\n",
        "\n",
        "results = audio_processor.get_features_for_wav(input_wav, model_settings,\n",
        "                                                 sess)\n",
        "features = results[0]\n",
        "\n",
        "features_min, features_max = input_data.get_features_range(model_settings)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvLeb5JMV-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_features = []\n",
        "\n",
        "for value in features.flatten():\n",
        "  quantized_value = int(round((255 * (value - features_min)) / (features_max - features_min)))\n",
        "  if quantized_value < 0:\n",
        "    quantized_value = 0\n",
        "  if quantized_value > 255:\n",
        "    quantized_value = 255\n",
        "  quantized_features.append(quantized_value)\n",
        "\n",
        "Reshape_1 = np.reshape(quantized_features, (49,10))  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCbj2PUqCRkw",
        "colab_type": "code",
        "outputId": "bb101fd4-eec9-429d-a707-d96b70351c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Reshape_1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xc-7ZujyWns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Reshape_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfUo554cWq1q",
        "colab_type": "code",
        "outputId": "735770b1-6c76-4bc7-de83-a964b21a912b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "graph_def_file = \"/content/speech_dscnn_172.pb\"\n",
        "input_arrays = [\"Reshape_1\"]\n",
        "output_arrays = [\"labels_softmax\"]\n",
        "input_shapes = {\"Reshape_1\": [1,49,10,1]}\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
        "  graph_def_file, input_arrays, output_arrays, input_shapes)\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model2.tflite\", \"wb\").write(tflite_model)\n",
        "print(input_arrays)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Reshape_1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9YBqDW2OU8B",
        "colab_type": "code",
        "outputId": "5cc940b3-e3a2-4676-d1a2-e34736185698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"converted_model2.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9218082e-01 1.4634981e-03 7.0478168e-04 5.6071795e-04 1.0309902e-03\n",
            "  4.5320328e-04 4.8955966e-04 3.7163886e-04 6.6869549e-04 6.1295443e-04\n",
            "  8.4630074e-04 6.1686942e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}